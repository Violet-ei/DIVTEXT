INFO -> 2025-12-08 09:19:44,364: sst2, args: Namespace(log_path='./log', dataset='sst2', save_path='./trained_model', model_type='bert-base-uncased', epochs=3, num_labels=2, lr=2e-05, max_len=128, batch_size=64, use_cuda=True, num_workers=32, seed=42, log_steps=50, eval_steps=50, eps=2.0, top_k=20, embedding_type='ct_vectors', mapping_strategy='conservative', privatization_strategy='s1', save_stop_words=False)
INFO -> 2025-12-08 09:21:02,201: train_data:67349, dev_data:872
INFO -> 2025-12-08 09:21:07,317: Init_val_acc: 0.503440
INFO -> 2025-12-08 09:21:07,317: Training model for 3 epochs..
INFO -> 2025-12-08 09:21:07,597: [Train] epoch:1/3, step: 0/3159, step_loss:0.7015
INFO -> 2025-12-08 09:21:47,621: [Evaluate] epoch:1/3, step: 50/3159, val_acc:0.69381
INFO -> 2025-12-08 09:21:47,979: [Evaluate] best accuracy performance has been updated: 0.50344 -> 0.69381
INFO -> 2025-12-08 09:21:48,442: [Train] epoch:1/3, step: 50/3159, step_loss:0.5810
INFO -> 2025-12-08 09:22:50,564: [Evaluate] epoch:1/3, step: 100/3159, val_acc:0.72477
INFO -> 2025-12-08 09:22:50,926: [Evaluate] best accuracy performance has been updated: 0.69381 -> 0.72477
INFO -> 2025-12-08 09:22:51,344: [Train] epoch:1/3, step: 100/3159, step_loss:0.5107
INFO -> 2025-12-08 09:23:53,953: [Evaluate] epoch:1/3, step: 150/3159, val_acc:0.73165
INFO -> 2025-12-08 09:23:54,293: [Evaluate] best accuracy performance has been updated: 0.72477 -> 0.73165
INFO -> 2025-12-08 09:23:54,699: [Train] epoch:1/3, step: 150/3159, step_loss:0.4425
INFO -> 2025-12-08 09:24:57,209: [Evaluate] epoch:1/3, step: 200/3159, val_acc:0.73968
INFO -> 2025-12-08 09:24:57,585: [Evaluate] best accuracy performance has been updated: 0.73165 -> 0.73968
INFO -> 2025-12-08 09:24:57,988: [Train] epoch:1/3, step: 200/3159, step_loss:0.5559
INFO -> 2025-12-08 09:26:00,635: [Evaluate] epoch:1/3, step: 250/3159, val_acc:0.73853
INFO -> 2025-12-08 09:26:01,058: [Train] epoch:1/3, step: 250/3159, step_loss:0.5282
INFO -> 2025-12-08 09:27:01,021: [Evaluate] epoch:1/3, step: 300/3159, val_acc:0.74541
INFO -> 2025-12-08 09:27:01,359: [Evaluate] best accuracy performance has been updated: 0.73968 -> 0.74541
INFO -> 2025-12-08 09:27:01,777: [Train] epoch:1/3, step: 300/3159, step_loss:0.5112
INFO -> 2025-12-08 09:28:04,479: [Evaluate] epoch:1/3, step: 350/3159, val_acc:0.75000
INFO -> 2025-12-08 09:28:04,824: [Evaluate] best accuracy performance has been updated: 0.74541 -> 0.75000
INFO -> 2025-12-08 09:28:05,251: [Train] epoch:1/3, step: 350/3159, step_loss:0.3827
INFO -> 2025-12-08 09:29:07,877: [Evaluate] epoch:1/3, step: 400/3159, val_acc:0.74771
INFO -> 2025-12-08 09:29:08,295: [Train] epoch:1/3, step: 400/3159, step_loss:0.4329
INFO -> 2025-12-08 09:30:10,889: [Evaluate] epoch:1/3, step: 450/3159, val_acc:0.73739
INFO -> 2025-12-08 09:30:11,316: [Train] epoch:1/3, step: 450/3159, step_loss:0.4682
INFO -> 2025-12-08 09:31:11,296: [Evaluate] epoch:1/3, step: 500/3159, val_acc:0.75344
INFO -> 2025-12-08 09:31:11,674: [Evaluate] best accuracy performance has been updated: 0.75000 -> 0.75344
INFO -> 2025-12-08 09:31:14,777: [Train] epoch:1/3, step: 500/3159, step_loss:0.4935
INFO -> 2025-12-08 09:32:14,949: [Evaluate] epoch:1/3, step: 550/3159, val_acc:0.76032
INFO -> 2025-12-08 09:32:15,277: [Evaluate] best accuracy performance has been updated: 0.75344 -> 0.76032
INFO -> 2025-12-08 09:32:15,688: [Train] epoch:1/3, step: 550/3159, step_loss:0.4047
INFO -> 2025-12-08 09:33:20,107: [Evaluate] epoch:1/3, step: 600/3159, val_acc:0.77179
INFO -> 2025-12-08 09:33:20,443: [Evaluate] best accuracy performance has been updated: 0.76032 -> 0.77179
INFO -> 2025-12-08 09:33:20,833: [Train] epoch:1/3, step: 600/3159, step_loss:0.3607
INFO -> 2025-12-08 09:34:22,098: [Evaluate] epoch:1/3, step: 650/3159, val_acc:0.78211
INFO -> 2025-12-08 09:34:22,434: [Evaluate] best accuracy performance has been updated: 0.77179 -> 0.78211
INFO -> 2025-12-08 09:34:22,863: [Train] epoch:1/3, step: 650/3159, step_loss:0.5203
INFO -> 2025-12-08 09:35:25,423: [Evaluate] epoch:1/3, step: 700/3159, val_acc:0.77408
INFO -> 2025-12-08 09:35:25,874: [Train] epoch:1/3, step: 700/3159, step_loss:0.4353
INFO -> 2025-12-08 09:36:25,715: [Evaluate] epoch:1/3, step: 750/3159, val_acc:0.78096
INFO -> 2025-12-08 09:36:26,153: [Train] epoch:1/3, step: 750/3159, step_loss:0.5462
INFO -> 2025-12-08 09:37:30,422: [Evaluate] epoch:1/3, step: 800/3159, val_acc:0.79472
INFO -> 2025-12-08 09:37:30,773: [Evaluate] best accuracy performance has been updated: 0.78211 -> 0.79472
INFO -> 2025-12-08 09:37:31,216: [Train] epoch:1/3, step: 800/3159, step_loss:0.4448
INFO -> 2025-12-08 09:38:32,788: [Evaluate] epoch:1/3, step: 850/3159, val_acc:0.79243
INFO -> 2025-12-08 09:38:33,215: [Train] epoch:1/3, step: 850/3159, step_loss:0.3792
INFO -> 2025-12-08 09:39:35,298: [Evaluate] epoch:1/3, step: 900/3159, val_acc:0.80161
INFO -> 2025-12-08 09:39:35,680: [Evaluate] best accuracy performance has been updated: 0.79472 -> 0.80161
INFO -> 2025-12-08 09:39:36,096: [Train] epoch:1/3, step: 900/3159, step_loss:0.3688
INFO -> 2025-12-08 09:40:38,875: [Evaluate] epoch:1/3, step: 950/3159, val_acc:0.77179
INFO -> 2025-12-08 09:40:39,306: [Train] epoch:1/3, step: 950/3159, step_loss:0.3337
INFO -> 2025-12-08 09:41:42,069: [Evaluate] epoch:1/3, step: 1000/3159, val_acc:0.80619
INFO -> 2025-12-08 09:41:42,458: [Evaluate] best accuracy performance has been updated: 0.80161 -> 0.80619
INFO -> 2025-12-08 09:41:42,909: [Train] epoch:1/3, step: 1000/3159, step_loss:0.4333
INFO -> 2025-12-08 09:42:42,958: [Evaluate] epoch:1/3, step: 1050/3159, val_acc:0.79472
INFO -> 2025-12-08 09:42:43,383: [Train] epoch:1/3, step: 1050/3159, step_loss:0.3858
INFO -> 2025-12-08 09:42:51,753: [Epoch 1] train_epoch_loss = 0.0073,  ---- val_acc = 0.7924,  [1297.9s]
INFO -> 2025-12-08 09:43:30,400: [Evaluate] epoch:2/3, step: 1100/3159, val_acc:0.78440
INFO -> 2025-12-08 09:43:30,823: [Train] epoch:2/3, step: 1100/3159, step_loss:0.3750
INFO -> 2025-12-08 09:44:32,275: [Evaluate] epoch:2/3, step: 1150/3159, val_acc:0.79128
INFO -> 2025-12-08 09:44:32,706: [Train] epoch:2/3, step: 1150/3159, step_loss:0.2815
INFO -> 2025-12-08 09:45:34,661: [Evaluate] epoch:2/3, step: 1200/3159, val_acc:0.79931
INFO -> 2025-12-08 09:45:35,078: [Train] epoch:2/3, step: 1200/3159, step_loss:0.2862
INFO -> 2025-12-08 09:46:37,664: [Evaluate] epoch:2/3, step: 1250/3159, val_acc:0.79472
INFO -> 2025-12-08 09:46:38,092: [Train] epoch:2/3, step: 1250/3159, step_loss:0.2959
INFO -> 2025-12-08 09:47:40,811: [Evaluate] epoch:2/3, step: 1300/3159, val_acc:0.79702
INFO -> 2025-12-08 09:47:41,224: [Train] epoch:2/3, step: 1300/3159, step_loss:0.3886
INFO -> 2025-12-08 09:48:43,856: [Evaluate] epoch:2/3, step: 1350/3159, val_acc:0.79128
INFO -> 2025-12-08 09:48:44,312: [Train] epoch:2/3, step: 1350/3159, step_loss:0.2944
INFO -> 2025-12-08 09:49:44,035: [Evaluate] epoch:2/3, step: 1400/3159, val_acc:0.80390
INFO -> 2025-12-08 09:49:44,458: [Train] epoch:2/3, step: 1400/3159, step_loss:0.3513
INFO -> 2025-12-08 09:50:47,525: [Evaluate] epoch:2/3, step: 1450/3159, val_acc:0.80734
INFO -> 2025-12-08 09:50:47,897: [Evaluate] best accuracy performance has been updated: 0.80619 -> 0.80734
INFO -> 2025-12-08 09:50:48,343: [Train] epoch:2/3, step: 1450/3159, step_loss:0.2503
INFO -> 2025-12-08 09:51:50,716: [Evaluate] epoch:2/3, step: 1500/3159, val_acc:0.79931
INFO -> 2025-12-08 09:51:51,140: [Train] epoch:2/3, step: 1500/3159, step_loss:0.3536
INFO -> 2025-12-08 09:52:53,689: [Evaluate] epoch:2/3, step: 1550/3159, val_acc:0.80849
INFO -> 2025-12-08 09:52:54,054: [Evaluate] best accuracy performance has been updated: 0.80734 -> 0.80849
INFO -> 2025-12-08 09:52:54,480: [Train] epoch:2/3, step: 1550/3159, step_loss:0.3236
INFO -> 2025-12-08 09:53:56,973: [Evaluate] epoch:2/3, step: 1600/3159, val_acc:0.81193
INFO -> 2025-12-08 09:53:57,333: [Evaluate] best accuracy performance has been updated: 0.80849 -> 0.81193
INFO -> 2025-12-08 09:53:57,739: [Train] epoch:2/3, step: 1600/3159, step_loss:0.2623
INFO -> 2025-12-08 09:54:57,856: [Evaluate] epoch:2/3, step: 1650/3159, val_acc:0.80963
INFO -> 2025-12-08 09:54:58,288: [Train] epoch:2/3, step: 1650/3159, step_loss:0.3384
INFO -> 2025-12-08 09:56:01,104: [Evaluate] epoch:2/3, step: 1700/3159, val_acc:0.79702
INFO -> 2025-12-08 09:56:01,536: [Train] epoch:2/3, step: 1700/3159, step_loss:0.2840
INFO -> 2025-12-08 09:57:04,377: [Evaluate] epoch:2/3, step: 1750/3159, val_acc:0.80619
INFO -> 2025-12-08 09:57:04,809: [Train] epoch:2/3, step: 1750/3159, step_loss:0.1652
INFO -> 2025-12-08 09:58:07,013: [Evaluate] epoch:2/3, step: 1800/3159, val_acc:0.80619
INFO -> 2025-12-08 09:58:07,435: [Train] epoch:2/3, step: 1800/3159, step_loss:0.3350
INFO -> 2025-12-08 09:59:10,251: [Evaluate] epoch:2/3, step: 1850/3159, val_acc:0.81422
INFO -> 2025-12-08 09:59:10,663: [Evaluate] best accuracy performance has been updated: 0.81193 -> 0.81422
INFO -> 2025-12-08 09:59:11,106: [Train] epoch:2/3, step: 1850/3159, step_loss:0.4018
INFO -> 2025-12-08 10:00:10,714: [Evaluate] epoch:2/3, step: 1900/3159, val_acc:0.81193
INFO -> 2025-12-08 10:00:11,139: [Train] epoch:2/3, step: 1900/3159, step_loss:0.4210
INFO -> 2025-12-08 10:01:13,771: [Evaluate] epoch:2/3, step: 1950/3159, val_acc:0.80963
INFO -> 2025-12-08 10:01:14,199: [Train] epoch:2/3, step: 1950/3159, step_loss:0.2752
INFO -> 2025-12-08 10:02:17,087: [Evaluate] epoch:2/3, step: 2000/3159, val_acc:0.81995
INFO -> 2025-12-08 10:02:17,448: [Evaluate] best accuracy performance has been updated: 0.81422 -> 0.81995
INFO -> 2025-12-08 10:02:17,867: [Train] epoch:2/3, step: 2000/3159, step_loss:0.4550
INFO -> 2025-12-08 10:03:20,740: [Evaluate] epoch:2/3, step: 2050/3159, val_acc:0.80963
INFO -> 2025-12-08 10:03:21,168: [Train] epoch:2/3, step: 2050/3159, step_loss:0.3646
INFO -> 2025-12-08 10:04:21,158: [Evaluate] epoch:2/3, step: 2100/3159, val_acc:0.81307
INFO -> 2025-12-08 10:04:21,579: [Train] epoch:2/3, step: 2100/3159, step_loss:0.3637
INFO -> 2025-12-08 10:04:33,307: [Epoch 2] train_epoch_loss = 0.0052,  ---- val_acc = 0.8096,  [1297.6s]
INFO -> 2025-12-08 10:05:09,593: [Evaluate] epoch:3/3, step: 2150/3159, val_acc:0.80161
INFO -> 2025-12-08 10:05:10,009: [Train] epoch:3/3, step: 2150/3159, step_loss:0.2053
INFO -> 2025-12-08 10:06:10,269: [Evaluate] epoch:3/3, step: 2200/3159, val_acc:0.80619
INFO -> 2025-12-08 10:06:13,101: [Train] epoch:3/3, step: 2200/3159, step_loss:0.2321
INFO -> 2025-12-08 10:07:13,178: [Evaluate] epoch:3/3, step: 2250/3159, val_acc:0.81307
INFO -> 2025-12-08 10:07:13,601: [Train] epoch:3/3, step: 2250/3159, step_loss:0.1965
INFO -> 2025-12-08 10:08:16,147: [Evaluate] epoch:3/3, step: 2300/3159, val_acc:0.80275
INFO -> 2025-12-08 10:08:16,562: [Train] epoch:3/3, step: 2300/3159, step_loss:0.1634
INFO -> 2025-12-08 10:09:19,109: [Evaluate] epoch:3/3, step: 2350/3159, val_acc:0.81078
INFO -> 2025-12-08 10:09:19,523: [Train] epoch:3/3, step: 2350/3159, step_loss:0.3293
INFO -> 2025-12-08 10:10:22,155: [Evaluate] epoch:3/3, step: 2400/3159, val_acc:0.81307
INFO -> 2025-12-08 10:10:22,576: [Train] epoch:3/3, step: 2400/3159, step_loss:0.2894
INFO -> 2025-12-08 10:11:22,895: [Evaluate] epoch:3/3, step: 2450/3159, val_acc:0.81422
INFO -> 2025-12-08 10:11:23,338: [Train] epoch:3/3, step: 2450/3159, step_loss:0.2565
INFO -> 2025-12-08 10:12:24,352: [Evaluate] epoch:3/3, step: 2500/3159, val_acc:0.81422
INFO -> 2025-12-08 10:12:24,859: [Train] epoch:3/3, step: 2500/3159, step_loss:0.1807
INFO -> 2025-12-08 10:13:29,290: [Evaluate] epoch:3/3, step: 2550/3159, val_acc:0.81422
INFO -> 2025-12-08 10:13:29,711: [Train] epoch:3/3, step: 2550/3159, step_loss:0.2292
INFO -> 2025-12-08 10:14:30,569: [Evaluate] epoch:3/3, step: 2600/3159, val_acc:0.81537
INFO -> 2025-12-08 10:14:31,025: [Train] epoch:3/3, step: 2600/3159, step_loss:0.1673
INFO -> 2025-12-08 10:15:33,107: [Evaluate] epoch:3/3, step: 2650/3159, val_acc:0.81193
INFO -> 2025-12-08 10:15:33,566: [Train] epoch:3/3, step: 2650/3159, step_loss:0.1782
INFO -> 2025-12-08 10:16:35,740: [Evaluate] epoch:3/3, step: 2700/3159, val_acc:0.81651
INFO -> 2025-12-08 10:16:36,197: [Train] epoch:3/3, step: 2700/3159, step_loss:0.1778
INFO -> 2025-12-08 10:17:38,425: [Evaluate] epoch:3/3, step: 2750/3159, val_acc:0.81078
INFO -> 2025-12-08 10:17:38,875: [Train] epoch:3/3, step: 2750/3159, step_loss:0.2029
INFO -> 2025-12-08 10:18:40,860: [Evaluate] epoch:3/3, step: 2800/3159, val_acc:0.82110
INFO -> 2025-12-08 10:18:41,291: [Evaluate] best accuracy performance has been updated: 0.81995 -> 0.82110
INFO -> 2025-12-08 10:18:41,726: [Train] epoch:3/3, step: 2800/3159, step_loss:0.3216
INFO -> 2025-12-08 10:19:43,999: [Evaluate] epoch:3/3, step: 2850/3159, val_acc:0.81881
INFO -> 2025-12-08 10:19:44,455: [Train] epoch:3/3, step: 2850/3159, step_loss:0.2526
INFO -> 2025-12-08 10:20:46,520: [Evaluate] epoch:3/3, step: 2900/3159, val_acc:0.81537
INFO -> 2025-12-08 10:20:46,979: [Train] epoch:3/3, step: 2900/3159, step_loss:0.2606
INFO -> 2025-12-08 10:21:49,136: [Evaluate] epoch:3/3, step: 2950/3159, val_acc:0.81995
INFO -> 2025-12-08 10:21:49,581: [Train] epoch:3/3, step: 2950/3159, step_loss:0.3121
INFO -> 2025-12-08 10:22:51,608: [Evaluate] epoch:3/3, step: 3000/3159, val_acc:0.81422
INFO -> 2025-12-08 10:22:52,075: [Train] epoch:3/3, step: 3000/3159, step_loss:0.1677
INFO -> 2025-12-08 10:23:54,170: [Evaluate] epoch:3/3, step: 3050/3159, val_acc:0.81881
INFO -> 2025-12-08 10:23:54,628: [Train] epoch:3/3, step: 3050/3159, step_loss:0.3367
INFO -> 2025-12-08 10:24:56,700: [Evaluate] epoch:3/3, step: 3100/3159, val_acc:0.81881
INFO -> 2025-12-08 10:24:57,163: [Train] epoch:3/3, step: 3100/3159, step_loss:0.1943
INFO -> 2025-12-08 10:25:59,334: [Evaluate] epoch:3/3, step: 3150/3159, val_acc:0.81881
INFO -> 2025-12-08 10:25:59,788: [Train] epoch:3/3, step: 3150/3159, step_loss:0.3166
INFO -> 2025-12-08 10:26:12,621: [Evaluate] epoch:3/3, step: 3158/3159, val_acc:0.81881
INFO -> 2025-12-08 10:26:16,857: [Epoch 3] train_epoch_loss = 0.0038,  ---- val_acc = 0.8188,  [1299.4s]
INFO -> 2025-12-08 10:26:16,858: -- Training done in 3909s.
INFO -> 2025-12-08 10:26:20,955: âœ… Final Dev Accuracy: 0.8211

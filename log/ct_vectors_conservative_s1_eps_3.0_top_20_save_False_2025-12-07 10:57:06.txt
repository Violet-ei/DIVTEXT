INFO -> 2025-12-07 10:57:06,899: sst2, args: Namespace(log_path='./log', dataset='sst2', save_path='./trained_model', model_type='bert-base-uncased', epochs=3, num_labels=2, lr=2e-05, max_len=128, batch_size=64, use_cuda=True, num_workers=32, seed=42, log_steps=50, eval_steps=50, eps=3.0, top_k=20, embedding_type='ct_vectors', mapping_strategy='conservative', privatization_strategy='s1', save_stop_words=False)
INFO -> 2025-12-07 10:57:44,016: train_data:67349, dev_data:872
INFO -> 2025-12-07 10:57:51,180: Init_val_acc: 0.526376
INFO -> 2025-12-07 10:57:51,180: Training model for 3 epochs..
INFO -> 2025-12-07 10:57:51,485: [Train] epoch:1/3, step: 0/3159, step_loss:0.6959
INFO -> 2025-12-07 10:58:31,456: [Evaluate] epoch:1/3, step: 50/3159, val_acc:0.65596
INFO -> 2025-12-07 10:58:31,927: [Evaluate] best accuracy performance has been updated: 0.52638 -> 0.65596
INFO -> 2025-12-07 10:58:32,676: [Train] epoch:1/3, step: 50/3159, step_loss:0.6426
INFO -> 2025-12-07 10:59:14,698: [Evaluate] epoch:1/3, step: 100/3159, val_acc:0.73624
INFO -> 2025-12-07 10:59:15,081: [Evaluate] best accuracy performance has been updated: 0.65596 -> 0.73624
INFO -> 2025-12-07 10:59:15,428: [Train] epoch:1/3, step: 100/3159, step_loss:0.6752
INFO -> 2025-12-07 10:59:57,436: [Evaluate] epoch:1/3, step: 150/3159, val_acc:0.75229
INFO -> 2025-12-07 10:59:57,810: [Evaluate] best accuracy performance has been updated: 0.73624 -> 0.75229
INFO -> 2025-12-07 10:59:58,081: [Train] epoch:1/3, step: 150/3159, step_loss:0.5410
INFO -> 2025-12-07 11:00:39,928: [Evaluate] epoch:1/3, step: 200/3159, val_acc:0.75344
INFO -> 2025-12-07 11:00:40,293: [Evaluate] best accuracy performance has been updated: 0.75229 -> 0.75344
INFO -> 2025-12-07 11:00:40,578: [Train] epoch:1/3, step: 200/3159, step_loss:0.4692
INFO -> 2025-12-07 11:03:18,150: [Evaluate] epoch:1/3, step: 250/3159, val_acc:0.75115
INFO -> 2025-12-07 11:03:19,914: [Train] epoch:1/3, step: 250/3159, step_loss:0.5149
INFO -> 2025-12-07 11:06:48,831: [Evaluate] epoch:1/3, step: 300/3159, val_acc:0.72936
INFO -> 2025-12-07 11:06:49,380: [Train] epoch:1/3, step: 300/3159, step_loss:0.3973
INFO -> 2025-12-07 11:09:50,957: [Evaluate] epoch:1/3, step: 350/3159, val_acc:0.75344
INFO -> 2025-12-07 11:09:53,357: [Train] epoch:1/3, step: 350/3159, step_loss:0.4956
INFO -> 2025-12-07 11:12:34,863: [Evaluate] epoch:1/3, step: 400/3159, val_acc:0.77294
INFO -> 2025-12-07 11:12:35,312: [Evaluate] best accuracy performance has been updated: 0.75344 -> 0.77294
INFO -> 2025-12-07 11:12:36,802: [Train] epoch:1/3, step: 400/3159, step_loss:0.4545
INFO -> 2025-12-07 11:15:07,126: [Evaluate] epoch:1/3, step: 450/3159, val_acc:0.75803
INFO -> 2025-12-07 11:15:08,797: [Train] epoch:1/3, step: 450/3159, step_loss:0.5043
INFO -> 2025-12-07 11:17:10,571: [Evaluate] epoch:1/3, step: 500/3159, val_acc:0.78670
INFO -> 2025-12-07 11:17:10,986: [Evaluate] best accuracy performance has been updated: 0.77294 -> 0.78670
INFO -> 2025-12-07 11:17:12,426: [Train] epoch:1/3, step: 500/3159, step_loss:0.5075
INFO -> 2025-12-07 11:19:16,455: [Evaluate] epoch:1/3, step: 550/3159, val_acc:0.78211
INFO -> 2025-12-07 11:19:16,913: [Train] epoch:1/3, step: 550/3159, step_loss:0.4017
INFO -> 2025-12-07 11:22:34,589: [Evaluate] epoch:1/3, step: 600/3159, val_acc:0.78326
INFO -> 2025-12-07 11:22:35,413: [Train] epoch:1/3, step: 600/3159, step_loss:0.3309
INFO -> 2025-12-07 11:26:23,178: [Evaluate] epoch:1/3, step: 650/3159, val_acc:0.76491
INFO -> 2025-12-07 11:26:24,141: [Train] epoch:1/3, step: 650/3159, step_loss:0.4840
INFO -> 2025-12-07 11:29:08,147: [Evaluate] epoch:1/3, step: 700/3159, val_acc:0.78326
INFO -> 2025-12-07 11:29:08,587: [Train] epoch:1/3, step: 700/3159, step_loss:0.3944
INFO -> 2025-12-07 11:30:08,561: [Evaluate] epoch:1/3, step: 750/3159, val_acc:0.77982
INFO -> 2025-12-07 11:30:09,011: [Train] epoch:1/3, step: 750/3159, step_loss:0.5913
INFO -> 2025-12-07 11:32:26,976: [Evaluate] epoch:1/3, step: 800/3159, val_acc:0.78211
INFO -> 2025-12-07 11:32:28,785: [Train] epoch:1/3, step: 800/3159, step_loss:0.5128
INFO -> 2025-12-07 11:35:05,314: [Evaluate] epoch:1/3, step: 850/3159, val_acc:0.79243
INFO -> 2025-12-07 11:35:05,752: [Evaluate] best accuracy performance has been updated: 0.78670 -> 0.79243
INFO -> 2025-12-07 11:35:08,358: [Train] epoch:1/3, step: 850/3159, step_loss:0.3410
INFO -> 2025-12-07 11:37:57,148: [Evaluate] epoch:1/3, step: 900/3159, val_acc:0.79931
INFO -> 2025-12-07 11:37:57,545: [Evaluate] best accuracy performance has been updated: 0.79243 -> 0.79931
INFO -> 2025-12-07 11:37:59,209: [Train] epoch:1/3, step: 900/3159, step_loss:0.3051
INFO -> 2025-12-07 11:40:24,484: [Evaluate] epoch:1/3, step: 950/3159, val_acc:0.78211
INFO -> 2025-12-07 11:40:26,183: [Train] epoch:1/3, step: 950/3159, step_loss:0.2811
INFO -> 2025-12-07 11:42:54,157: [Evaluate] epoch:1/3, step: 1000/3159, val_acc:0.80619
INFO -> 2025-12-07 11:42:54,537: [Evaluate] best accuracy performance has been updated: 0.79931 -> 0.80619
INFO -> 2025-12-07 11:42:54,966: [Train] epoch:1/3, step: 1000/3159, step_loss:0.5540
INFO -> 2025-12-07 11:45:25,894: [Evaluate] epoch:1/3, step: 1050/3159, val_acc:0.79587
INFO -> 2025-12-07 11:45:27,701: [Train] epoch:1/3, step: 1050/3159, step_loss:0.4770
INFO -> 2025-12-07 11:45:39,973: [Epoch 1] train_epoch_loss = 0.0073,  ---- val_acc = 0.7890,  [2861.0s]
INFO -> 2025-12-07 11:46:59,059: [Evaluate] epoch:2/3, step: 1100/3159, val_acc:0.78670
INFO -> 2025-12-07 11:46:59,505: [Train] epoch:2/3, step: 1100/3159, step_loss:0.3519
INFO -> 2025-12-07 11:47:59,221: [Evaluate] epoch:2/3, step: 1150/3159, val_acc:0.79931
INFO -> 2025-12-07 11:47:59,662: [Train] epoch:2/3, step: 1150/3159, step_loss:0.3477
INFO -> 2025-12-07 11:48:59,698: [Evaluate] epoch:2/3, step: 1200/3159, val_acc:0.80161
INFO -> 2025-12-07 11:49:00,146: [Train] epoch:2/3, step: 1200/3159, step_loss:0.1774
INFO -> 2025-12-07 11:49:59,798: [Evaluate] epoch:2/3, step: 1250/3159, val_acc:0.79702
INFO -> 2025-12-07 11:50:00,257: [Train] epoch:2/3, step: 1250/3159, step_loss:0.3363
INFO -> 2025-12-07 11:51:00,006: [Evaluate] epoch:2/3, step: 1300/3159, val_acc:0.79587
INFO -> 2025-12-07 11:51:00,454: [Train] epoch:2/3, step: 1300/3159, step_loss:0.3712
INFO -> 2025-12-07 11:52:00,033: [Evaluate] epoch:2/3, step: 1350/3159, val_acc:0.79931
INFO -> 2025-12-07 11:52:00,482: [Train] epoch:2/3, step: 1350/3159, step_loss:0.3539
INFO -> 2025-12-07 11:53:00,227: [Evaluate] epoch:2/3, step: 1400/3159, val_acc:0.79587
INFO -> 2025-12-07 11:53:00,654: [Train] epoch:2/3, step: 1400/3159, step_loss:0.3836
INFO -> 2025-12-07 11:54:00,263: [Evaluate] epoch:2/3, step: 1450/3159, val_acc:0.78899
INFO -> 2025-12-07 11:54:00,714: [Train] epoch:2/3, step: 1450/3159, step_loss:0.2748
INFO -> 2025-12-07 11:55:00,474: [Evaluate] epoch:2/3, step: 1500/3159, val_acc:0.79702
INFO -> 2025-12-07 11:55:00,914: [Train] epoch:2/3, step: 1500/3159, step_loss:0.3424
INFO -> 2025-12-07 11:56:00,613: [Evaluate] epoch:2/3, step: 1550/3159, val_acc:0.79472
INFO -> 2025-12-07 11:56:01,073: [Train] epoch:2/3, step: 1550/3159, step_loss:0.2495
INFO -> 2025-12-07 11:57:00,713: [Evaluate] epoch:2/3, step: 1600/3159, val_acc:0.80390
INFO -> 2025-12-07 11:57:01,161: [Train] epoch:2/3, step: 1600/3159, step_loss:0.2793
INFO -> 2025-12-07 11:58:02,607: [Evaluate] epoch:2/3, step: 1650/3159, val_acc:0.78211
INFO -> 2025-12-07 11:58:03,066: [Train] epoch:2/3, step: 1650/3159, step_loss:0.3320
INFO -> 2025-12-07 11:59:03,025: [Evaluate] epoch:2/3, step: 1700/3159, val_acc:0.76720
INFO -> 2025-12-07 11:59:03,470: [Train] epoch:2/3, step: 1700/3159, step_loss:0.3911
INFO -> 2025-12-07 12:00:03,090: [Evaluate] epoch:2/3, step: 1750/3159, val_acc:0.79817
INFO -> 2025-12-07 12:00:03,529: [Train] epoch:2/3, step: 1750/3159, step_loss:0.1891
INFO -> 2025-12-07 12:01:03,262: [Evaluate] epoch:2/3, step: 1800/3159, val_acc:0.79587
INFO -> 2025-12-07 12:01:03,727: [Train] epoch:2/3, step: 1800/3159, step_loss:0.3172
INFO -> 2025-12-07 12:02:03,434: [Evaluate] epoch:2/3, step: 1850/3159, val_acc:0.79587
INFO -> 2025-12-07 12:02:03,887: [Train] epoch:2/3, step: 1850/3159, step_loss:0.2464
INFO -> 2025-12-07 12:03:03,449: [Evaluate] epoch:2/3, step: 1900/3159, val_acc:0.79702
INFO -> 2025-12-07 12:03:03,894: [Train] epoch:2/3, step: 1900/3159, step_loss:0.3501
INFO -> 2025-12-07 12:04:03,423: [Evaluate] epoch:2/3, step: 1950/3159, val_acc:0.78670
INFO -> 2025-12-07 12:04:03,878: [Train] epoch:2/3, step: 1950/3159, step_loss:0.2458
INFO -> 2025-12-07 12:05:03,596: [Evaluate] epoch:2/3, step: 2000/3159, val_acc:0.80046
INFO -> 2025-12-07 12:05:04,046: [Train] epoch:2/3, step: 2000/3159, step_loss:0.4262
INFO -> 2025-12-07 12:06:03,489: [Evaluate] epoch:2/3, step: 2050/3159, val_acc:0.79931
INFO -> 2025-12-07 12:06:03,930: [Train] epoch:2/3, step: 2050/3159, step_loss:0.3345
INFO -> 2025-12-07 12:07:03,792: [Evaluate] epoch:2/3, step: 2100/3159, val_acc:0.80849
INFO -> 2025-12-07 12:07:04,206: [Evaluate] best accuracy performance has been updated: 0.80619 -> 0.80849
INFO -> 2025-12-07 12:07:04,643: [Train] epoch:2/3, step: 2100/3159, step_loss:0.3125
INFO -> 2025-12-07 12:07:14,024: [Epoch 2] train_epoch_loss = 0.0050,  ---- val_acc = 0.8211,  [1290.0s]
INFO -> 2025-12-07 12:07:51,367: [Evaluate] epoch:3/3, step: 2150/3159, val_acc:0.80390
INFO -> 2025-12-07 12:07:51,825: [Train] epoch:3/3, step: 2150/3159, step_loss:0.1615
INFO -> 2025-12-07 12:08:51,485: [Evaluate] epoch:3/3, step: 2200/3159, val_acc:0.80275
INFO -> 2025-12-07 12:08:51,932: [Train] epoch:3/3, step: 2200/3159, step_loss:0.2714
INFO -> 2025-12-07 12:09:51,527: [Evaluate] epoch:3/3, step: 2250/3159, val_acc:0.79702
INFO -> 2025-12-07 12:09:51,972: [Train] epoch:3/3, step: 2250/3159, step_loss:0.2542
INFO -> 2025-12-07 12:10:51,677: [Evaluate] epoch:3/3, step: 2300/3159, val_acc:0.80161
INFO -> 2025-12-07 12:10:52,132: [Train] epoch:3/3, step: 2300/3159, step_loss:0.2062
INFO -> 2025-12-07 12:11:51,783: [Evaluate] epoch:3/3, step: 2350/3159, val_acc:0.79472
INFO -> 2025-12-07 12:11:52,236: [Train] epoch:3/3, step: 2350/3159, step_loss:0.2699
INFO -> 2025-12-07 12:12:51,788: [Evaluate] epoch:3/3, step: 2400/3159, val_acc:0.80046
INFO -> 2025-12-07 12:12:52,241: [Train] epoch:3/3, step: 2400/3159, step_loss:0.1991
INFO -> 2025-12-07 12:13:52,103: [Evaluate] epoch:3/3, step: 2450/3159, val_acc:0.79702
INFO -> 2025-12-07 12:13:52,552: [Train] epoch:3/3, step: 2450/3159, step_loss:0.2301
INFO -> 2025-12-07 12:14:52,261: [Evaluate] epoch:3/3, step: 2500/3159, val_acc:0.80161
INFO -> 2025-12-07 12:14:52,712: [Train] epoch:3/3, step: 2500/3159, step_loss:0.1349
INFO -> 2025-12-07 12:15:52,190: [Evaluate] epoch:3/3, step: 2550/3159, val_acc:0.80161
INFO -> 2025-12-07 12:15:52,634: [Train] epoch:3/3, step: 2550/3159, step_loss:0.2395
INFO -> 2025-12-07 12:16:52,129: [Evaluate] epoch:3/3, step: 2600/3159, val_acc:0.79931
INFO -> 2025-12-07 12:16:52,591: [Train] epoch:3/3, step: 2600/3159, step_loss:0.3014
INFO -> 2025-12-07 12:17:52,099: [Evaluate] epoch:3/3, step: 2650/3159, val_acc:0.80275
INFO -> 2025-12-07 12:17:52,552: [Train] epoch:3/3, step: 2650/3159, step_loss:0.2101
INFO -> 2025-12-07 12:18:52,011: [Evaluate] epoch:3/3, step: 2700/3159, val_acc:0.80161
INFO -> 2025-12-07 12:18:52,470: [Train] epoch:3/3, step: 2700/3159, step_loss:0.1469
INFO -> 2025-12-07 12:19:52,301: [Evaluate] epoch:3/3, step: 2750/3159, val_acc:0.80275
INFO -> 2025-12-07 12:19:52,753: [Train] epoch:3/3, step: 2750/3159, step_loss:0.2341
INFO -> 2025-12-07 12:20:52,384: [Evaluate] epoch:3/3, step: 2800/3159, val_acc:0.80390
INFO -> 2025-12-07 12:20:52,828: [Train] epoch:3/3, step: 2800/3159, step_loss:0.3715
INFO -> 2025-12-07 12:21:52,451: [Evaluate] epoch:3/3, step: 2850/3159, val_acc:0.79931
INFO -> 2025-12-07 12:21:52,892: [Train] epoch:3/3, step: 2850/3159, step_loss:0.1872
INFO -> 2025-12-07 12:22:52,641: [Evaluate] epoch:3/3, step: 2900/3159, val_acc:0.80275
INFO -> 2025-12-07 12:22:53,102: [Train] epoch:3/3, step: 2900/3159, step_loss:0.2792
INFO -> 2025-12-07 12:23:52,878: [Evaluate] epoch:3/3, step: 2950/3159, val_acc:0.80275
INFO -> 2025-12-07 12:23:53,322: [Train] epoch:3/3, step: 2950/3159, step_loss:0.2419
INFO -> 2025-12-07 12:24:53,021: [Evaluate] epoch:3/3, step: 3000/3159, val_acc:0.80046
INFO -> 2025-12-07 12:24:53,478: [Train] epoch:3/3, step: 3000/3159, step_loss:0.1949
INFO -> 2025-12-07 12:25:53,018: [Evaluate] epoch:3/3, step: 3050/3159, val_acc:0.80046
INFO -> 2025-12-07 12:25:53,472: [Train] epoch:3/3, step: 3050/3159, step_loss:0.2627
INFO -> 2025-12-07 12:26:53,070: [Evaluate] epoch:3/3, step: 3100/3159, val_acc:0.80619
INFO -> 2025-12-07 12:26:53,521: [Train] epoch:3/3, step: 3100/3159, step_loss:0.2143
INFO -> 2025-12-07 12:27:53,068: [Evaluate] epoch:3/3, step: 3150/3159, val_acc:0.80046
INFO -> 2025-12-07 12:27:53,511: [Train] epoch:3/3, step: 3150/3159, step_loss:0.2104
INFO -> 2025-12-07 12:28:06,114: [Evaluate] epoch:3/3, step: 3158/3159, val_acc:0.79931
INFO -> 2025-12-07 12:28:10,548: [Epoch 3] train_epoch_loss = 0.0036,  ---- val_acc = 0.7993,  [1252.2s]
INFO -> 2025-12-07 12:28:10,548: -- Training done in 5419s.
INFO -> 2025-12-07 12:28:14,658: âœ… Final Dev Accuracy: 0.8085

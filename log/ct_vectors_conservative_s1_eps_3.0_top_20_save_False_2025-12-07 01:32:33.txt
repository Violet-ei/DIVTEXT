INFO -> 2025-12-07 01:32:33,233: sst2, args: Namespace(log_path='./log', dataset='sst2', save_path='./trained_model', model_type='bert-base-uncased', epochs=3, num_labels=2, lr=2e-05, max_len=128, batch_size=64, use_cuda=True, num_workers=32, seed=42, log_steps=50, eval_steps=50, eps=3.0, top_k=20, embedding_type='ct_vectors', mapping_strategy='conservative', privatization_strategy='s1', save_stop_words=False)
INFO -> 2025-12-07 01:33:09,810: train_data:67349, dev_data:872
INFO -> 2025-12-07 01:33:15,274: Init_val_acc: 0.509174
INFO -> 2025-12-07 01:33:15,274: Training model for 3 epochs..
INFO -> 2025-12-07 01:33:15,595: [Train] epoch:1/3, step: 0/3159, step_loss:0.6964
INFO -> 2025-12-07 01:34:05,311: [Evaluate] epoch:1/3, step: 50/3159, val_acc:0.84862
INFO -> 2025-12-07 01:34:05,870: [Evaluate] best accuracy performance has been updated: 0.50917 -> 0.84862
INFO -> 2025-12-07 01:34:06,625: [Train] epoch:1/3, step: 50/3159, step_loss:0.6348
INFO -> 2025-12-07 01:35:57,894: [Evaluate] epoch:1/3, step: 100/3159, val_acc:0.86697
INFO -> 2025-12-07 01:35:58,359: [Evaluate] best accuracy performance has been updated: 0.84862 -> 0.86697
INFO -> 2025-12-07 01:35:58,812: [Train] epoch:1/3, step: 100/3159, step_loss:0.5360
INFO -> 2025-12-07 01:36:59,113: [Evaluate] epoch:1/3, step: 150/3159, val_acc:0.86239
INFO -> 2025-12-07 01:36:59,548: [Train] epoch:1/3, step: 150/3159, step_loss:0.5291
INFO -> 2025-12-07 01:38:00,357: [Evaluate] epoch:1/3, step: 200/3159, val_acc:0.88188
INFO -> 2025-12-07 01:38:00,726: [Evaluate] best accuracy performance has been updated: 0.86697 -> 0.88188
INFO -> 2025-12-07 01:38:01,187: [Train] epoch:1/3, step: 200/3159, step_loss:0.4464
INFO -> 2025-12-07 01:39:01,988: [Evaluate] epoch:1/3, step: 250/3159, val_acc:0.88647
INFO -> 2025-12-07 01:39:02,346: [Evaluate] best accuracy performance has been updated: 0.88188 -> 0.88647
INFO -> 2025-12-07 01:39:03,217: [Train] epoch:1/3, step: 250/3159, step_loss:0.5423
INFO -> 2025-12-07 01:40:05,319: [Evaluate] epoch:1/3, step: 300/3159, val_acc:0.89679
INFO -> 2025-12-07 01:40:05,705: [Evaluate] best accuracy performance has been updated: 0.88647 -> 0.89679
INFO -> 2025-12-07 01:40:06,161: [Train] epoch:1/3, step: 300/3159, step_loss:0.5297
INFO -> 2025-12-07 01:41:07,163: [Evaluate] epoch:1/3, step: 350/3159, val_acc:0.88647
INFO -> 2025-12-07 01:41:07,619: [Train] epoch:1/3, step: 350/3159, step_loss:0.3933
INFO -> 2025-12-07 01:42:08,517: [Evaluate] epoch:1/3, step: 400/3159, val_acc:0.89450
INFO -> 2025-12-07 01:42:08,969: [Train] epoch:1/3, step: 400/3159, step_loss:0.4550
INFO -> 2025-12-07 01:43:09,982: [Evaluate] epoch:1/3, step: 450/3159, val_acc:0.88188
INFO -> 2025-12-07 01:43:10,454: [Train] epoch:1/3, step: 450/3159, step_loss:0.4950
INFO -> 2025-12-07 01:44:15,281: [Evaluate] epoch:1/3, step: 500/3159, val_acc:0.90023
INFO -> 2025-12-07 01:44:15,681: [Evaluate] best accuracy performance has been updated: 0.89679 -> 0.90023
INFO -> 2025-12-07 01:44:16,200: [Train] epoch:1/3, step: 500/3159, step_loss:0.5050
INFO -> 2025-12-07 01:45:42,713: [Evaluate] epoch:1/3, step: 550/3159, val_acc:0.89794
INFO -> 2025-12-07 01:45:43,165: [Train] epoch:1/3, step: 550/3159, step_loss:0.4633
INFO -> 2025-12-07 01:46:48,595: [Evaluate] epoch:1/3, step: 600/3159, val_acc:0.89335
INFO -> 2025-12-07 01:46:49,110: [Train] epoch:1/3, step: 600/3159, step_loss:0.3959
INFO -> 2025-12-07 01:48:03,189: [Evaluate] epoch:1/3, step: 650/3159, val_acc:0.89564
INFO -> 2025-12-07 01:48:03,645: [Train] epoch:1/3, step: 650/3159, step_loss:0.4605
INFO -> 2025-12-07 01:49:09,802: [Evaluate] epoch:1/3, step: 700/3159, val_acc:0.89450
INFO -> 2025-12-07 01:49:10,260: [Train] epoch:1/3, step: 700/3159, step_loss:0.3863
INFO -> 2025-12-07 01:50:17,463: [Evaluate] epoch:1/3, step: 750/3159, val_acc:0.90596
INFO -> 2025-12-07 01:50:18,002: [Evaluate] best accuracy performance has been updated: 0.90023 -> 0.90596
INFO -> 2025-12-07 01:50:18,572: [Train] epoch:1/3, step: 750/3159, step_loss:0.4918
INFO -> 2025-12-07 01:51:46,869: [Evaluate] epoch:1/3, step: 800/3159, val_acc:0.90138
INFO -> 2025-12-07 01:51:47,454: [Train] epoch:1/3, step: 800/3159, step_loss:0.5103
INFO -> 2025-12-07 01:53:05,073: [Evaluate] epoch:1/3, step: 850/3159, val_acc:0.89794
INFO -> 2025-12-07 01:53:05,773: [Train] epoch:1/3, step: 850/3159, step_loss:0.3094
INFO -> 2025-12-07 01:54:43,005: [Evaluate] epoch:1/3, step: 900/3159, val_acc:0.89450
INFO -> 2025-12-07 01:54:43,940: [Train] epoch:1/3, step: 900/3159, step_loss:0.3623
INFO -> 2025-12-07 01:55:50,311: [Evaluate] epoch:1/3, step: 950/3159, val_acc:0.86927
INFO -> 2025-12-07 01:55:51,167: [Train] epoch:1/3, step: 950/3159, step_loss:0.3358
INFO -> 2025-12-07 01:56:53,756: [Evaluate] epoch:1/3, step: 1000/3159, val_acc:0.90940
INFO -> 2025-12-07 01:56:54,248: [Evaluate] best accuracy performance has been updated: 0.90596 -> 0.90940
INFO -> 2025-12-07 01:56:54,690: [Train] epoch:1/3, step: 1000/3159, step_loss:0.4461
INFO -> 2025-12-07 01:57:57,660: [Evaluate] epoch:1/3, step: 1050/3159, val_acc:0.91628
INFO -> 2025-12-07 01:57:58,066: [Evaluate] best accuracy performance has been updated: 0.90940 -> 0.91628
INFO -> 2025-12-07 01:57:58,524: [Train] epoch:1/3, step: 1050/3159, step_loss:0.5431
INFO -> 2025-12-07 01:58:06,401: [Epoch 1] train_epoch_loss = 0.0072,  ---- val_acc = 0.9197,  [1486.1s]
INFO -> 2025-12-07 01:58:47,714: [Evaluate] epoch:2/3, step: 1100/3159, val_acc:0.90023
INFO -> 2025-12-07 01:58:48,280: [Train] epoch:2/3, step: 1100/3159, step_loss:0.3358
INFO -> 2025-12-07 01:59:51,642: [Evaluate] epoch:2/3, step: 1150/3159, val_acc:0.92202
INFO -> 2025-12-07 01:59:52,022: [Evaluate] best accuracy performance has been updated: 0.91628 -> 0.92202
INFO -> 2025-12-07 01:59:52,477: [Train] epoch:2/3, step: 1150/3159, step_loss:0.3228
INFO -> 2025-12-07 02:00:55,047: [Evaluate] epoch:2/3, step: 1200/3159, val_acc:0.90367
INFO -> 2025-12-07 02:00:55,906: [Train] epoch:2/3, step: 1200/3159, step_loss:0.2017
INFO -> 2025-12-07 02:01:59,073: [Evaluate] epoch:2/3, step: 1250/3159, val_acc:0.91628
INFO -> 2025-12-07 02:01:59,889: [Train] epoch:2/3, step: 1250/3159, step_loss:0.3669
INFO -> 2025-12-07 02:03:02,734: [Evaluate] epoch:2/3, step: 1300/3159, val_acc:0.91628
INFO -> 2025-12-07 02:03:03,489: [Train] epoch:2/3, step: 1300/3159, step_loss:0.3049
INFO -> 2025-12-07 02:04:06,343: [Evaluate] epoch:2/3, step: 1350/3159, val_acc:0.91399
INFO -> 2025-12-07 02:04:07,696: [Train] epoch:2/3, step: 1350/3159, step_loss:0.3443
INFO -> 2025-12-07 02:05:10,094: [Evaluate] epoch:2/3, step: 1400/3159, val_acc:0.91628
INFO -> 2025-12-07 02:05:10,545: [Train] epoch:2/3, step: 1400/3159, step_loss:0.3038
INFO -> 2025-12-07 02:06:11,786: [Evaluate] epoch:2/3, step: 1450/3159, val_acc:0.91399
INFO -> 2025-12-07 02:06:12,242: [Train] epoch:2/3, step: 1450/3159, step_loss:0.3276
INFO -> 2025-12-07 02:07:13,379: [Evaluate] epoch:2/3, step: 1500/3159, val_acc:0.91858
INFO -> 2025-12-07 02:07:13,841: [Train] epoch:2/3, step: 1500/3159, step_loss:0.3445
INFO -> 2025-12-07 02:08:15,155: [Evaluate] epoch:2/3, step: 1550/3159, val_acc:0.90940
INFO -> 2025-12-07 02:08:15,611: [Train] epoch:2/3, step: 1550/3159, step_loss:0.2850
INFO -> 2025-12-07 02:09:17,292: [Evaluate] epoch:2/3, step: 1600/3159, val_acc:0.90711
INFO -> 2025-12-07 02:09:17,771: [Train] epoch:2/3, step: 1600/3159, step_loss:0.2600
INFO -> 2025-12-07 02:10:18,576: [Evaluate] epoch:2/3, step: 1650/3159, val_acc:0.90138
INFO -> 2025-12-07 02:10:19,026: [Train] epoch:2/3, step: 1650/3159, step_loss:0.2753
INFO -> 2025-12-07 02:11:20,198: [Evaluate] epoch:2/3, step: 1700/3159, val_acc:0.88876
INFO -> 2025-12-07 02:11:20,650: [Train] epoch:2/3, step: 1700/3159, step_loss:0.3953
INFO -> 2025-12-07 02:12:21,818: [Evaluate] epoch:2/3, step: 1750/3159, val_acc:0.90826
INFO -> 2025-12-07 02:12:22,287: [Train] epoch:2/3, step: 1750/3159, step_loss:0.3602
INFO -> 2025-12-07 02:13:23,269: [Evaluate] epoch:2/3, step: 1800/3159, val_acc:0.90711
INFO -> 2025-12-07 02:13:23,730: [Train] epoch:2/3, step: 1800/3159, step_loss:0.2787
INFO -> 2025-12-07 02:14:24,849: [Evaluate] epoch:2/3, step: 1850/3159, val_acc:0.90711
INFO -> 2025-12-07 02:14:25,301: [Train] epoch:2/3, step: 1850/3159, step_loss:0.3314
INFO -> 2025-12-07 02:15:26,254: [Evaluate] epoch:2/3, step: 1900/3159, val_acc:0.90252
INFO -> 2025-12-07 02:15:26,717: [Train] epoch:2/3, step: 1900/3159, step_loss:0.3342
INFO -> 2025-12-07 02:16:27,821: [Evaluate] epoch:2/3, step: 1950/3159, val_acc:0.90023
INFO -> 2025-12-07 02:16:28,287: [Train] epoch:2/3, step: 1950/3159, step_loss:0.3049
INFO -> 2025-12-07 02:17:29,415: [Evaluate] epoch:2/3, step: 2000/3159, val_acc:0.91055
INFO -> 2025-12-07 02:17:29,858: [Train] epoch:2/3, step: 2000/3159, step_loss:0.3583
INFO -> 2025-12-07 02:18:30,708: [Evaluate] epoch:2/3, step: 2050/3159, val_acc:0.91743
INFO -> 2025-12-07 02:18:31,189: [Train] epoch:2/3, step: 2050/3159, step_loss:0.2498
INFO -> 2025-12-07 02:19:32,245: [Evaluate] epoch:2/3, step: 2100/3159, val_acc:0.92661
INFO -> 2025-12-07 02:19:32,703: [Evaluate] best accuracy performance has been updated: 0.92202 -> 0.92661
INFO -> 2025-12-07 02:19:33,169: [Train] epoch:2/3, step: 2100/3159, step_loss:0.2925
INFO -> 2025-12-07 02:19:42,649: [Epoch 2] train_epoch_loss = 0.0050,  ---- val_acc = 0.9278,  [1292.2s]
INFO -> 2025-12-07 02:20:19,844: [Evaluate] epoch:3/3, step: 2150/3159, val_acc:0.92202
INFO -> 2025-12-07 02:20:20,305: [Train] epoch:3/3, step: 2150/3159, step_loss:0.1530
INFO -> 2025-12-07 02:21:21,285: [Evaluate] epoch:3/3, step: 2200/3159, val_acc:0.92202
INFO -> 2025-12-07 02:21:21,752: [Train] epoch:3/3, step: 2200/3159, step_loss:0.2337
INFO -> 2025-12-07 02:22:23,068: [Evaluate] epoch:3/3, step: 2250/3159, val_acc:0.90826
INFO -> 2025-12-07 02:22:23,518: [Train] epoch:3/3, step: 2250/3159, step_loss:0.1661
INFO -> 2025-12-07 02:23:24,293: [Evaluate] epoch:3/3, step: 2300/3159, val_acc:0.92317
INFO -> 2025-12-07 02:23:24,763: [Train] epoch:3/3, step: 2300/3159, step_loss:0.1709
INFO -> 2025-12-07 02:24:25,906: [Evaluate] epoch:3/3, step: 2350/3159, val_acc:0.90596
INFO -> 2025-12-07 02:24:26,357: [Train] epoch:3/3, step: 2350/3159, step_loss:0.2484
INFO -> 2025-12-07 02:25:27,092: [Evaluate] epoch:3/3, step: 2400/3159, val_acc:0.91284
INFO -> 2025-12-07 02:25:27,553: [Train] epoch:3/3, step: 2400/3159, step_loss:0.1656
INFO -> 2025-12-07 02:26:28,480: [Evaluate] epoch:3/3, step: 2450/3159, val_acc:0.91170
INFO -> 2025-12-07 02:26:28,942: [Train] epoch:3/3, step: 2450/3159, step_loss:0.3163
INFO -> 2025-12-07 02:27:29,928: [Evaluate] epoch:3/3, step: 2500/3159, val_acc:0.90482
INFO -> 2025-12-07 02:27:30,387: [Train] epoch:3/3, step: 2500/3159, step_loss:0.1400
INFO -> 2025-12-07 02:28:31,508: [Evaluate] epoch:3/3, step: 2550/3159, val_acc:0.91055
INFO -> 2025-12-07 02:28:31,974: [Train] epoch:3/3, step: 2550/3159, step_loss:0.1100
INFO -> 2025-12-07 02:29:32,817: [Evaluate] epoch:3/3, step: 2600/3159, val_acc:0.90711
INFO -> 2025-12-07 02:29:33,278: [Train] epoch:3/3, step: 2600/3159, step_loss:0.2433
INFO -> 2025-12-07 02:30:34,257: [Evaluate] epoch:3/3, step: 2650/3159, val_acc:0.90940
INFO -> 2025-12-07 02:30:34,722: [Train] epoch:3/3, step: 2650/3159, step_loss:0.2228
INFO -> 2025-12-07 02:31:35,596: [Evaluate] epoch:3/3, step: 2700/3159, val_acc:0.91628
INFO -> 2025-12-07 02:31:36,048: [Train] epoch:3/3, step: 2700/3159, step_loss:0.1166
INFO -> 2025-12-07 02:32:37,016: [Evaluate] epoch:3/3, step: 2750/3159, val_acc:0.91514
INFO -> 2025-12-07 02:32:37,487: [Train] epoch:3/3, step: 2750/3159, step_loss:0.1804
INFO -> 2025-12-07 02:33:38,336: [Evaluate] epoch:3/3, step: 2800/3159, val_acc:0.90711
INFO -> 2025-12-07 02:33:38,807: [Train] epoch:3/3, step: 2800/3159, step_loss:0.2568
INFO -> 2025-12-07 02:34:39,749: [Evaluate] epoch:3/3, step: 2850/3159, val_acc:0.91055
INFO -> 2025-12-07 02:34:40,209: [Train] epoch:3/3, step: 2850/3159, step_loss:0.2791
INFO -> 2025-12-07 02:35:41,807: [Evaluate] epoch:3/3, step: 2900/3159, val_acc:0.91170
INFO -> 2025-12-07 02:35:42,250: [Train] epoch:3/3, step: 2900/3159, step_loss:0.2751
INFO -> 2025-12-07 02:36:43,490: [Evaluate] epoch:3/3, step: 2950/3159, val_acc:0.91399
INFO -> 2025-12-07 02:36:43,955: [Train] epoch:3/3, step: 2950/3159, step_loss:0.1557
INFO -> 2025-12-07 02:37:44,855: [Evaluate] epoch:3/3, step: 3000/3159, val_acc:0.91858
INFO -> 2025-12-07 02:37:45,329: [Train] epoch:3/3, step: 3000/3159, step_loss:0.1967
INFO -> 2025-12-07 02:38:46,280: [Evaluate] epoch:3/3, step: 3050/3159, val_acc:0.91514
INFO -> 2025-12-07 02:38:46,740: [Train] epoch:3/3, step: 3050/3159, step_loss:0.3247
INFO -> 2025-12-07 02:39:47,861: [Evaluate] epoch:3/3, step: 3100/3159, val_acc:0.91399
INFO -> 2025-12-07 02:39:48,330: [Train] epoch:3/3, step: 3100/3159, step_loss:0.2665
INFO -> 2025-12-07 02:40:49,250: [Evaluate] epoch:3/3, step: 3150/3159, val_acc:0.91628
INFO -> 2025-12-07 02:40:49,698: [Train] epoch:3/3, step: 3150/3159, step_loss:0.2627
INFO -> 2025-12-07 02:41:03,003: [Evaluate] epoch:3/3, step: 3158/3159, val_acc:0.91628
INFO -> 2025-12-07 02:41:07,490: [Epoch 3] train_epoch_loss = 0.0036,  ---- val_acc = 0.9163,  [1280.5s]
INFO -> 2025-12-07 02:41:07,490: -- Training done in 4072s.
INFO -> 2025-12-07 02:41:11,678: âœ… Final Dev Accuracy: 0.9266

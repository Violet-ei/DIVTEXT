INFO -> 2025-12-08 22:41:00,516: sst2, args: Namespace(log_path='./log', dataset='sst2', save_path='./trained_model', model_type='bert-base-uncased', epochs=3, num_labels=2, lr=2e-05, max_len=128, batch_size=64, use_cuda=True, num_workers=32, seed=42, log_steps=50, eval_steps=50, eps=2.0, top_k=20, embedding_type='ct_vectors', mapping_strategy='conservative', privatization_strategy='s1', save_stop_words=True)
INFO -> 2025-12-08 22:41:53,498: train_data:67349, dev_data:872
INFO -> 2025-12-08 22:42:01,994: Init_val_acc: 0.516055
INFO -> 2025-12-08 22:42:01,994: Training model for 3 epochs..
INFO -> 2025-12-08 22:42:02,285: [Train] epoch:1/3, step: 0/3159, step_loss:0.6922
INFO -> 2025-12-08 22:42:42,735: [Evaluate] epoch:1/3, step: 50/3159, val_acc:0.75803
INFO -> 2025-12-08 22:42:43,105: [Evaluate] best accuracy performance has been updated: 0.51606 -> 0.75803
INFO -> 2025-12-08 22:42:43,654: [Train] epoch:1/3, step: 50/3159, step_loss:0.5689
INFO -> 2025-12-08 22:43:45,451: [Evaluate] epoch:1/3, step: 100/3159, val_acc:0.79128
INFO -> 2025-12-08 22:43:45,944: [Evaluate] best accuracy performance has been updated: 0.75803 -> 0.79128
INFO -> 2025-12-08 22:43:46,390: [Train] epoch:1/3, step: 100/3159, step_loss:0.4348
INFO -> 2025-12-08 22:44:51,172: [Evaluate] epoch:1/3, step: 150/3159, val_acc:0.78326
INFO -> 2025-12-08 22:44:51,640: [Train] epoch:1/3, step: 150/3159, step_loss:0.4140
INFO -> 2025-12-08 22:45:49,117: [Evaluate] epoch:1/3, step: 200/3159, val_acc:0.79931
INFO -> 2025-12-08 22:45:49,500: [Evaluate] best accuracy performance has been updated: 0.79128 -> 0.79931
INFO -> 2025-12-08 22:45:49,913: [Train] epoch:1/3, step: 200/3159, step_loss:0.4298
INFO -> 2025-12-08 22:46:50,823: [Evaluate] epoch:1/3, step: 250/3159, val_acc:0.80619
INFO -> 2025-12-08 22:46:51,181: [Evaluate] best accuracy performance has been updated: 0.79931 -> 0.80619
INFO -> 2025-12-08 22:46:51,583: [Train] epoch:1/3, step: 250/3159, step_loss:0.4255
INFO -> 2025-12-08 22:47:52,180: [Evaluate] epoch:1/3, step: 300/3159, val_acc:0.79587
INFO -> 2025-12-08 22:47:52,628: [Train] epoch:1/3, step: 300/3159, step_loss:0.3749
INFO -> 2025-12-08 22:48:50,982: [Evaluate] epoch:1/3, step: 350/3159, val_acc:0.82110
INFO -> 2025-12-08 22:48:51,371: [Evaluate] best accuracy performance has been updated: 0.80619 -> 0.82110
INFO -> 2025-12-08 22:48:51,793: [Train] epoch:1/3, step: 350/3159, step_loss:0.3524
INFO -> 2025-12-08 22:49:52,735: [Evaluate] epoch:1/3, step: 400/3159, val_acc:0.81537
INFO -> 2025-12-08 22:49:53,148: [Train] epoch:1/3, step: 400/3159, step_loss:0.4958
INFO -> 2025-12-08 22:50:51,378: [Evaluate] epoch:1/3, step: 450/3159, val_acc:0.78096
INFO -> 2025-12-08 22:50:51,812: [Train] epoch:1/3, step: 450/3159, step_loss:0.4453
INFO -> 2025-12-08 22:51:53,212: [Evaluate] epoch:1/3, step: 500/3159, val_acc:0.81881
INFO -> 2025-12-08 22:51:53,641: [Train] epoch:1/3, step: 500/3159, step_loss:0.3596
INFO -> 2025-12-08 22:52:54,366: [Evaluate] epoch:1/3, step: 550/3159, val_acc:0.82225
INFO -> 2025-12-08 22:52:54,735: [Evaluate] best accuracy performance has been updated: 0.82110 -> 0.82225
INFO -> 2025-12-08 22:52:55,161: [Train] epoch:1/3, step: 550/3159, step_loss:0.3057
INFO -> 2025-12-08 22:53:55,710: [Evaluate] epoch:1/3, step: 600/3159, val_acc:0.81078
INFO -> 2025-12-08 22:53:56,158: [Train] epoch:1/3, step: 600/3159, step_loss:0.2722
INFO -> 2025-12-08 22:54:54,485: [Evaluate] epoch:1/3, step: 650/3159, val_acc:0.81995
INFO -> 2025-12-08 22:54:54,907: [Train] epoch:1/3, step: 650/3159, step_loss:0.5000
INFO -> 2025-12-08 22:55:55,705: [Evaluate] epoch:1/3, step: 700/3159, val_acc:0.82798
INFO -> 2025-12-08 22:55:56,164: [Evaluate] best accuracy performance has been updated: 0.82225 -> 0.82798
INFO -> 2025-12-08 22:55:56,572: [Train] epoch:1/3, step: 700/3159, step_loss:0.3210
INFO -> 2025-12-08 22:56:57,287: [Evaluate] epoch:1/3, step: 750/3159, val_acc:0.83257
INFO -> 2025-12-08 22:56:57,650: [Evaluate] best accuracy performance has been updated: 0.82798 -> 0.83257
INFO -> 2025-12-08 22:56:58,061: [Train] epoch:1/3, step: 750/3159, step_loss:0.6407
INFO -> 2025-12-08 22:57:55,953: [Evaluate] epoch:1/3, step: 800/3159, val_acc:0.83142
INFO -> 2025-12-08 22:57:58,975: [Train] epoch:1/3, step: 800/3159, step_loss:0.2839
INFO -> 2025-12-08 22:58:57,199: [Evaluate] epoch:1/3, step: 850/3159, val_acc:0.83486
INFO -> 2025-12-08 22:58:57,541: [Evaluate] best accuracy performance has been updated: 0.83257 -> 0.83486
INFO -> 2025-12-08 22:58:57,956: [Train] epoch:1/3, step: 850/3159, step_loss:0.3306
INFO -> 2025-12-08 22:59:58,833: [Evaluate] epoch:1/3, step: 900/3159, val_acc:0.83142
INFO -> 2025-12-08 22:59:59,258: [Train] epoch:1/3, step: 900/3159, step_loss:0.3023
INFO -> 2025-12-08 23:00:58,558: [Evaluate] epoch:1/3, step: 950/3159, val_acc:0.83028
INFO -> 2025-12-08 23:00:58,973: [Train] epoch:1/3, step: 950/3159, step_loss:0.2898
INFO -> 2025-12-08 23:01:59,650: [Evaluate] epoch:1/3, step: 1000/3159, val_acc:0.83028
INFO -> 2025-12-08 23:02:00,065: [Train] epoch:1/3, step: 1000/3159, step_loss:0.4319
INFO -> 2025-12-08 23:03:00,705: [Evaluate] epoch:1/3, step: 1050/3159, val_acc:0.82798
INFO -> 2025-12-08 23:03:01,130: [Train] epoch:1/3, step: 1050/3159, step_loss:0.4002
INFO -> 2025-12-08 23:03:06,808: [Epoch 1] train_epoch_loss = 0.0064,  ---- val_acc = 0.8257,  [1261.0s]
INFO -> 2025-12-08 23:03:45,891: [Evaluate] epoch:2/3, step: 1100/3159, val_acc:0.82913
INFO -> 2025-12-08 23:03:46,307: [Train] epoch:2/3, step: 1100/3159, step_loss:0.2486
INFO -> 2025-12-08 23:04:48,756: [Evaluate] epoch:2/3, step: 1150/3159, val_acc:0.83830
INFO -> 2025-12-08 23:04:49,111: [Evaluate] best accuracy performance has been updated: 0.83486 -> 0.83830
INFO -> 2025-12-08 23:04:49,522: [Train] epoch:2/3, step: 1150/3159, step_loss:0.2787
INFO -> 2025-12-08 23:05:51,732: [Evaluate] epoch:2/3, step: 1200/3159, val_acc:0.83486
INFO -> 2025-12-08 23:05:52,549: [Train] epoch:2/3, step: 1200/3159, step_loss:0.2282
INFO -> 2025-12-08 23:06:52,281: [Evaluate] epoch:2/3, step: 1250/3159, val_acc:0.83028
INFO -> 2025-12-08 23:06:52,849: [Train] epoch:2/3, step: 1250/3159, step_loss:0.2474
INFO -> 2025-12-08 23:07:55,490: [Evaluate] epoch:2/3, step: 1300/3159, val_acc:0.83142
INFO -> 2025-12-08 23:07:56,035: [Train] epoch:2/3, step: 1300/3159, step_loss:0.2667
INFO -> 2025-12-08 23:08:58,527: [Evaluate] epoch:2/3, step: 1350/3159, val_acc:0.83716
INFO -> 2025-12-08 23:08:59,786: [Train] epoch:2/3, step: 1350/3159, step_loss:0.2461
INFO -> 2025-12-08 23:10:02,088: [Evaluate] epoch:2/3, step: 1400/3159, val_acc:0.83716
INFO -> 2025-12-08 23:10:02,850: [Train] epoch:2/3, step: 1400/3159, step_loss:0.2607
INFO -> 2025-12-08 23:11:02,036: [Evaluate] epoch:2/3, step: 1450/3159, val_acc:0.83601
INFO -> 2025-12-08 23:11:02,836: [Train] epoch:2/3, step: 1450/3159, step_loss:0.1467
INFO -> 2025-12-08 23:12:05,673: [Evaluate] epoch:2/3, step: 1500/3159, val_acc:0.83372
INFO -> 2025-12-08 23:12:06,301: [Train] epoch:2/3, step: 1500/3159, step_loss:0.3021
INFO -> 2025-12-08 23:13:09,367: [Evaluate] epoch:2/3, step: 1550/3159, val_acc:0.83601
INFO -> 2025-12-08 23:13:10,586: [Train] epoch:2/3, step: 1550/3159, step_loss:0.1860
INFO -> 2025-12-08 23:14:13,175: [Evaluate] epoch:2/3, step: 1600/3159, val_acc:0.83486
INFO -> 2025-12-08 23:14:13,660: [Train] epoch:2/3, step: 1600/3159, step_loss:0.2902
INFO -> 2025-12-08 23:15:13,404: [Evaluate] epoch:2/3, step: 1650/3159, val_acc:0.83486
INFO -> 2025-12-08 23:15:17,342: [Train] epoch:2/3, step: 1650/3159, step_loss:0.1807
INFO -> 2025-12-08 23:16:17,109: [Evaluate] epoch:2/3, step: 1700/3159, val_acc:0.83142
INFO -> 2025-12-08 23:16:18,339: [Train] epoch:2/3, step: 1700/3159, step_loss:0.3910
INFO -> 2025-12-08 23:17:20,769: [Evaluate] epoch:2/3, step: 1750/3159, val_acc:0.83257
INFO -> 2025-12-08 23:17:21,366: [Train] epoch:2/3, step: 1750/3159, step_loss:0.1758
INFO -> 2025-12-08 23:18:23,716: [Evaluate] epoch:2/3, step: 1800/3159, val_acc:0.84404
INFO -> 2025-12-08 23:18:24,140: [Evaluate] best accuracy performance has been updated: 0.83830 -> 0.84404
INFO -> 2025-12-08 23:18:24,554: [Train] epoch:2/3, step: 1800/3159, step_loss:0.2331
INFO -> 2025-12-08 23:19:27,226: [Evaluate] epoch:2/3, step: 1850/3159, val_acc:0.83716
INFO -> 2025-12-08 23:19:28,482: [Train] epoch:2/3, step: 1850/3159, step_loss:0.3807
INFO -> 2025-12-08 23:20:28,093: [Evaluate] epoch:2/3, step: 1900/3159, val_acc:0.84174
INFO -> 2025-12-08 23:20:28,573: [Train] epoch:2/3, step: 1900/3159, step_loss:0.2530
INFO -> 2025-12-08 23:21:31,184: [Evaluate] epoch:2/3, step: 1950/3159, val_acc:0.83716
INFO -> 2025-12-08 23:21:31,729: [Train] epoch:2/3, step: 1950/3159, step_loss:0.2111
INFO -> 2025-12-08 23:22:34,214: [Evaluate] epoch:2/3, step: 2000/3159, val_acc:0.84518
INFO -> 2025-12-08 23:22:34,593: [Evaluate] best accuracy performance has been updated: 0.84404 -> 0.84518
INFO -> 2025-12-08 23:22:34,984: [Train] epoch:2/3, step: 2000/3159, step_loss:0.3344
INFO -> 2025-12-08 23:23:37,313: [Evaluate] epoch:2/3, step: 2050/3159, val_acc:0.85206
INFO -> 2025-12-08 23:23:37,678: [Evaluate] best accuracy performance has been updated: 0.84518 -> 0.85206
INFO -> 2025-12-08 23:23:38,087: [Train] epoch:2/3, step: 2050/3159, step_loss:0.2693
INFO -> 2025-12-08 23:24:40,301: [Evaluate] epoch:2/3, step: 2100/3159, val_acc:0.84748
INFO -> 2025-12-08 23:24:41,546: [Train] epoch:2/3, step: 2100/3159, step_loss:0.2125
INFO -> 2025-12-08 23:24:52,037: [Epoch 2] train_epoch_loss = 0.0040,  ---- val_acc = 0.8463,  [1300.7s]
INFO -> 2025-12-08 23:25:30,624: [Evaluate] epoch:3/3, step: 2150/3159, val_acc:0.84862
INFO -> 2025-12-08 23:25:31,471: [Train] epoch:3/3, step: 2150/3159, step_loss:0.1395
INFO -> 2025-12-08 23:26:33,797: [Evaluate] epoch:3/3, step: 2200/3159, val_acc:0.85321
INFO -> 2025-12-08 23:26:34,158: [Evaluate] best accuracy performance has been updated: 0.85206 -> 0.85321
INFO -> 2025-12-08 23:26:34,561: [Train] epoch:3/3, step: 2200/3159, step_loss:0.1950
INFO -> 2025-12-08 23:27:36,756: [Evaluate] epoch:3/3, step: 2250/3159, val_acc:0.82913
INFO -> 2025-12-08 23:27:37,989: [Train] epoch:3/3, step: 2250/3159, step_loss:0.1734
INFO -> 2025-12-08 23:28:37,547: [Evaluate] epoch:3/3, step: 2300/3159, val_acc:0.83945
INFO -> 2025-12-08 23:28:38,177: [Train] epoch:3/3, step: 2300/3159, step_loss:0.1060
INFO -> 2025-12-08 23:29:40,584: [Evaluate] epoch:3/3, step: 2350/3159, val_acc:0.84060
INFO -> 2025-12-08 23:29:41,236: [Train] epoch:3/3, step: 2350/3159, step_loss:0.2054
INFO -> 2025-12-08 23:30:43,596: [Evaluate] epoch:3/3, step: 2400/3159, val_acc:0.84633
INFO -> 2025-12-08 23:30:44,215: [Train] epoch:3/3, step: 2400/3159, step_loss:0.2056
INFO -> 2025-12-08 23:31:55,426: [Evaluate] epoch:3/3, step: 2450/3159, val_acc:0.84174
INFO -> 2025-12-08 23:31:57,151: [Train] epoch:3/3, step: 2450/3159, step_loss:0.2154
INFO -> 2025-12-08 23:33:04,640: [Evaluate] epoch:3/3, step: 2500/3159, val_acc:0.83830
INFO -> 2025-12-08 23:33:05,062: [Train] epoch:3/3, step: 2500/3159, step_loss:0.0795
INFO -> 2025-12-08 23:34:06,826: [Evaluate] epoch:3/3, step: 2550/3159, val_acc:0.83486
INFO -> 2025-12-08 23:34:07,248: [Train] epoch:3/3, step: 2550/3159, step_loss:0.2670
INFO -> 2025-12-08 23:35:06,444: [Evaluate] epoch:3/3, step: 2600/3159, val_acc:0.83830
INFO -> 2025-12-08 23:35:06,857: [Train] epoch:3/3, step: 2600/3159, step_loss:0.1256
INFO -> 2025-12-08 23:36:17,149: [Evaluate] epoch:3/3, step: 2650/3159, val_acc:0.82913
INFO -> 2025-12-08 23:36:17,604: [Train] epoch:3/3, step: 2650/3159, step_loss:0.1998
INFO -> 2025-12-08 23:37:24,795: [Evaluate] epoch:3/3, step: 2700/3159, val_acc:0.83945
INFO -> 2025-12-08 23:37:25,254: [Train] epoch:3/3, step: 2700/3159, step_loss:0.1232
INFO -> 2025-12-08 23:38:32,044: [Evaluate] epoch:3/3, step: 2750/3159, val_acc:0.83601
INFO -> 2025-12-08 23:38:32,501: [Train] epoch:3/3, step: 2750/3159, step_loss:0.1216
INFO -> 2025-12-08 23:39:39,771: [Evaluate] epoch:3/3, step: 2800/3159, val_acc:0.83142
INFO -> 2025-12-08 23:39:40,219: [Train] epoch:3/3, step: 2800/3159, step_loss:0.2286
INFO -> 2025-12-08 23:40:44,157: [Evaluate] epoch:3/3, step: 2850/3159, val_acc:0.83486
INFO -> 2025-12-08 23:40:44,616: [Train] epoch:3/3, step: 2850/3159, step_loss:0.1577
INFO -> 2025-12-08 23:41:52,203: [Evaluate] epoch:3/3, step: 2900/3159, val_acc:0.83945
INFO -> 2025-12-08 23:41:53,006: [Train] epoch:3/3, step: 2900/3159, step_loss:0.2283
INFO -> 2025-12-08 23:42:59,574: [Evaluate] epoch:3/3, step: 2950/3159, val_acc:0.83601
INFO -> 2025-12-08 23:43:00,025: [Train] epoch:3/3, step: 2950/3159, step_loss:0.2604
INFO -> 2025-12-08 23:44:06,650: [Evaluate] epoch:3/3, step: 3000/3159, val_acc:0.83716
INFO -> 2025-12-08 23:44:07,093: [Train] epoch:3/3, step: 3000/3159, step_loss:0.1482
INFO -> 2025-12-08 23:45:13,901: [Evaluate] epoch:3/3, step: 3050/3159, val_acc:0.83486
INFO -> 2025-12-08 23:45:14,361: [Train] epoch:3/3, step: 3050/3159, step_loss:0.2231
INFO -> 2025-12-08 23:46:21,059: [Evaluate] epoch:3/3, step: 3100/3159, val_acc:0.83716
INFO -> 2025-12-08 23:46:21,517: [Train] epoch:3/3, step: 3100/3159, step_loss:0.1140
INFO -> 2025-12-08 23:47:27,786: [Evaluate] epoch:3/3, step: 3150/3159, val_acc:0.83486
INFO -> 2025-12-08 23:47:28,235: [Train] epoch:3/3, step: 3150/3159, step_loss:0.1116
INFO -> 2025-12-08 23:47:41,244: [Evaluate] epoch:3/3, step: 3158/3159, val_acc:0.83601
INFO -> 2025-12-08 23:47:45,707: [Epoch 3] train_epoch_loss = 0.0027,  ---- val_acc = 0.8360,  [1369.3s]
INFO -> 2025-12-08 23:47:45,707: -- Training done in 3943s.
INFO -> 2025-12-08 23:47:50,349: âœ… Final Dev Accuracy: 0.8532

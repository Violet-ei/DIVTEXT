INFO -> 2025-12-08 21:29:35,607: sst2, args: Namespace(log_path='./log', dataset='sst2', save_path='./trained_model', model_type='bert-base-uncased', epochs=3, num_labels=2, lr=2e-05, max_len=128, batch_size=64, use_cuda=True, num_workers=32, seed=42, log_steps=50, eval_steps=50, eps=1.0, top_k=20, embedding_type='ct_vectors', mapping_strategy='conservative', privatization_strategy='s1', save_stop_words=True)
INFO -> 2025-12-08 21:30:25,664: train_data:67349, dev_data:872
INFO -> 2025-12-08 21:30:31,665: Init_val_acc: 0.529817
INFO -> 2025-12-08 21:30:31,665: Training model for 3 epochs..
INFO -> 2025-12-08 21:30:31,935: [Train] epoch:1/3, step: 0/3159, step_loss:0.6979
INFO -> 2025-12-08 21:31:10,847: [Evaluate] epoch:1/3, step: 50/3159, val_acc:0.76376
INFO -> 2025-12-08 21:31:11,248: [Evaluate] best accuracy performance has been updated: 0.52982 -> 0.76376
INFO -> 2025-12-08 21:31:11,756: [Train] epoch:1/3, step: 50/3159, step_loss:0.4999
INFO -> 2025-12-08 21:32:19,996: [Evaluate] epoch:1/3, step: 100/3159, val_acc:0.77523
INFO -> 2025-12-08 21:32:20,373: [Evaluate] best accuracy performance has been updated: 0.76376 -> 0.77523
INFO -> 2025-12-08 21:32:20,798: [Train] epoch:1/3, step: 100/3159, step_loss:0.4870
INFO -> 2025-12-08 21:33:35,123: [Evaluate] epoch:1/3, step: 150/3159, val_acc:0.77294
INFO -> 2025-12-08 21:33:35,630: [Train] epoch:1/3, step: 150/3159, step_loss:0.5482
INFO -> 2025-12-08 21:34:48,105: [Evaluate] epoch:1/3, step: 200/3159, val_acc:0.79472
INFO -> 2025-12-08 21:34:48,590: [Evaluate] best accuracy performance has been updated: 0.77523 -> 0.79472
INFO -> 2025-12-08 21:34:49,038: [Train] epoch:1/3, step: 200/3159, step_loss:0.4601
INFO -> 2025-12-08 21:35:53,654: [Evaluate] epoch:1/3, step: 250/3159, val_acc:0.77179
INFO -> 2025-12-08 21:35:54,142: [Train] epoch:1/3, step: 250/3159, step_loss:0.6581
INFO -> 2025-12-08 21:37:00,638: [Evaluate] epoch:1/3, step: 300/3159, val_acc:0.79358
INFO -> 2025-12-08 21:37:01,105: [Train] epoch:1/3, step: 300/3159, step_loss:0.4119
INFO -> 2025-12-08 21:38:09,481: [Evaluate] epoch:1/3, step: 350/3159, val_acc:0.78670
INFO -> 2025-12-08 21:38:10,992: [Train] epoch:1/3, step: 350/3159, step_loss:0.3969
INFO -> 2025-12-08 21:39:28,983: [Evaluate] epoch:1/3, step: 400/3159, val_acc:0.79702
INFO -> 2025-12-08 21:39:29,381: [Evaluate] best accuracy performance has been updated: 0.79472 -> 0.79702
INFO -> 2025-12-08 21:39:29,804: [Train] epoch:1/3, step: 400/3159, step_loss:0.4533
INFO -> 2025-12-08 21:40:48,774: [Evaluate] epoch:1/3, step: 450/3159, val_acc:0.80505
INFO -> 2025-12-08 21:40:49,218: [Evaluate] best accuracy performance has been updated: 0.79702 -> 0.80505
INFO -> 2025-12-08 21:40:49,686: [Train] epoch:1/3, step: 450/3159, step_loss:0.4927
INFO -> 2025-12-08 21:41:51,591: [Evaluate] epoch:1/3, step: 500/3159, val_acc:0.80734
INFO -> 2025-12-08 21:41:51,924: [Evaluate] best accuracy performance has been updated: 0.80505 -> 0.80734
INFO -> 2025-12-08 21:41:52,342: [Train] epoch:1/3, step: 500/3159, step_loss:0.3960
INFO -> 2025-12-08 21:42:56,804: [Evaluate] epoch:1/3, step: 550/3159, val_acc:0.81766
INFO -> 2025-12-08 21:42:57,165: [Evaluate] best accuracy performance has been updated: 0.80734 -> 0.81766
INFO -> 2025-12-08 21:42:57,581: [Train] epoch:1/3, step: 550/3159, step_loss:0.4005
INFO -> 2025-12-08 21:44:04,129: [Evaluate] epoch:1/3, step: 600/3159, val_acc:0.81995
INFO -> 2025-12-08 21:44:04,520: [Evaluate] best accuracy performance has been updated: 0.81766 -> 0.81995
INFO -> 2025-12-08 21:44:04,983: [Train] epoch:1/3, step: 600/3159, step_loss:0.4365
INFO -> 2025-12-08 21:45:07,022: [Evaluate] epoch:1/3, step: 650/3159, val_acc:0.82683
INFO -> 2025-12-08 21:45:07,416: [Evaluate] best accuracy performance has been updated: 0.81995 -> 0.82683
INFO -> 2025-12-08 21:45:10,047: [Train] epoch:1/3, step: 650/3159, step_loss:0.4400
INFO -> 2025-12-08 21:46:10,408: [Evaluate] epoch:1/3, step: 700/3159, val_acc:0.82569
INFO -> 2025-12-08 21:46:10,857: [Train] epoch:1/3, step: 700/3159, step_loss:0.3557
INFO -> 2025-12-08 21:47:19,533: [Evaluate] epoch:1/3, step: 750/3159, val_acc:0.81766
INFO -> 2025-12-08 21:47:20,073: [Train] epoch:1/3, step: 750/3159, step_loss:0.5182
INFO -> 2025-12-08 21:48:25,676: [Evaluate] epoch:1/3, step: 800/3159, val_acc:0.81881
INFO -> 2025-12-08 21:48:26,140: [Train] epoch:1/3, step: 800/3159, step_loss:0.3663
INFO -> 2025-12-08 21:49:34,692: [Evaluate] epoch:1/3, step: 850/3159, val_acc:0.82569
INFO -> 2025-12-08 21:49:35,227: [Train] epoch:1/3, step: 850/3159, step_loss:0.2997
INFO -> 2025-12-08 21:50:50,944: [Evaluate] epoch:1/3, step: 900/3159, val_acc:0.83372
INFO -> 2025-12-08 21:50:51,347: [Evaluate] best accuracy performance has been updated: 0.82683 -> 0.83372
INFO -> 2025-12-08 21:50:51,835: [Train] epoch:1/3, step: 900/3159, step_loss:0.3315
INFO -> 2025-12-08 21:51:57,190: [Evaluate] epoch:1/3, step: 950/3159, val_acc:0.83716
INFO -> 2025-12-08 21:51:57,540: [Evaluate] best accuracy performance has been updated: 0.83372 -> 0.83716
INFO -> 2025-12-08 21:51:57,978: [Train] epoch:1/3, step: 950/3159, step_loss:0.2910
INFO -> 2025-12-08 21:53:00,483: [Evaluate] epoch:1/3, step: 1000/3159, val_acc:0.83945
INFO -> 2025-12-08 21:53:00,855: [Evaluate] best accuracy performance has been updated: 0.83716 -> 0.83945
INFO -> 2025-12-08 21:53:01,331: [Train] epoch:1/3, step: 1000/3159, step_loss:0.3281
INFO -> 2025-12-08 21:54:14,422: [Evaluate] epoch:1/3, step: 1050/3159, val_acc:0.82913
INFO -> 2025-12-08 21:54:14,894: [Train] epoch:1/3, step: 1050/3159, step_loss:0.4742
INFO -> 2025-12-08 21:54:20,931: [Epoch 1] train_epoch_loss = 0.0065,  ---- val_acc = 0.8349,  [1425.3s]
INFO -> 2025-12-08 21:55:00,232: [Evaluate] epoch:2/3, step: 1100/3159, val_acc:0.84174
INFO -> 2025-12-08 21:55:00,578: [Evaluate] best accuracy performance has been updated: 0.83945 -> 0.84174
INFO -> 2025-12-08 21:55:01,001: [Train] epoch:2/3, step: 1100/3159, step_loss:0.3097
INFO -> 2025-12-08 21:56:06,121: [Evaluate] epoch:2/3, step: 1150/3159, val_acc:0.83945
INFO -> 2025-12-08 21:56:06,573: [Train] epoch:2/3, step: 1150/3159, step_loss:0.2845
INFO -> 2025-12-08 21:57:08,106: [Evaluate] epoch:2/3, step: 1200/3159, val_acc:0.84404
INFO -> 2025-12-08 21:57:08,457: [Evaluate] best accuracy performance has been updated: 0.84174 -> 0.84404
INFO -> 2025-12-08 21:57:08,883: [Train] epoch:2/3, step: 1200/3159, step_loss:0.2713
INFO -> 2025-12-08 21:58:14,162: [Evaluate] epoch:2/3, step: 1250/3159, val_acc:0.83372
INFO -> 2025-12-08 21:58:14,626: [Train] epoch:2/3, step: 1250/3159, step_loss:0.2462
INFO -> 2025-12-08 21:59:19,458: [Evaluate] epoch:2/3, step: 1300/3159, val_acc:0.83945
INFO -> 2025-12-08 21:59:19,898: [Train] epoch:2/3, step: 1300/3159, step_loss:0.2201
INFO -> 2025-12-08 22:00:25,017: [Evaluate] epoch:2/3, step: 1350/3159, val_acc:0.83830
INFO -> 2025-12-08 22:00:25,445: [Train] epoch:2/3, step: 1350/3159, step_loss:0.3513
INFO -> 2025-12-08 22:01:30,390: [Evaluate] epoch:2/3, step: 1400/3159, val_acc:0.83142
INFO -> 2025-12-08 22:01:30,842: [Train] epoch:2/3, step: 1400/3159, step_loss:0.3251
INFO -> 2025-12-08 22:02:34,827: [Evaluate] epoch:2/3, step: 1450/3159, val_acc:0.83716
INFO -> 2025-12-08 22:02:35,286: [Train] epoch:2/3, step: 1450/3159, step_loss:0.2245
INFO -> 2025-12-08 22:03:39,715: [Evaluate] epoch:2/3, step: 1500/3159, val_acc:0.83028
INFO -> 2025-12-08 22:03:40,168: [Train] epoch:2/3, step: 1500/3159, step_loss:0.3696
INFO -> 2025-12-08 22:04:44,146: [Evaluate] epoch:2/3, step: 1550/3159, val_acc:0.83830
INFO -> 2025-12-08 22:04:44,587: [Train] epoch:2/3, step: 1550/3159, step_loss:0.2014
INFO -> 2025-12-08 22:05:49,674: [Evaluate] epoch:2/3, step: 1600/3159, val_acc:0.83830
INFO -> 2025-12-08 22:05:50,116: [Train] epoch:2/3, step: 1600/3159, step_loss:0.2460
INFO -> 2025-12-08 22:06:55,309: [Evaluate] epoch:2/3, step: 1650/3159, val_acc:0.83601
INFO -> 2025-12-08 22:06:55,763: [Train] epoch:2/3, step: 1650/3159, step_loss:0.2657
INFO -> 2025-12-08 22:08:00,836: [Evaluate] epoch:2/3, step: 1700/3159, val_acc:0.83028
INFO -> 2025-12-08 22:08:01,317: [Train] epoch:2/3, step: 1700/3159, step_loss:0.3707
INFO -> 2025-12-08 22:09:06,736: [Evaluate] epoch:2/3, step: 1750/3159, val_acc:0.83716
INFO -> 2025-12-08 22:09:07,189: [Train] epoch:2/3, step: 1750/3159, step_loss:0.1899
INFO -> 2025-12-08 22:10:08,443: [Evaluate] epoch:2/3, step: 1800/3159, val_acc:0.84748
INFO -> 2025-12-08 22:10:08,858: [Evaluate] best accuracy performance has been updated: 0.84404 -> 0.84748
INFO -> 2025-12-08 22:10:09,329: [Train] epoch:2/3, step: 1800/3159, step_loss:0.2370
INFO -> 2025-12-08 22:11:15,575: [Evaluate] epoch:2/3, step: 1850/3159, val_acc:0.84174
INFO -> 2025-12-08 22:11:16,042: [Train] epoch:2/3, step: 1850/3159, step_loss:0.3577
INFO -> 2025-12-08 22:12:20,732: [Evaluate] epoch:2/3, step: 1900/3159, val_acc:0.84633
INFO -> 2025-12-08 22:12:21,189: [Train] epoch:2/3, step: 1900/3159, step_loss:0.1875
INFO -> 2025-12-08 22:13:26,176: [Evaluate] epoch:2/3, step: 1950/3159, val_acc:0.83945
INFO -> 2025-12-08 22:13:26,638: [Train] epoch:2/3, step: 1950/3159, step_loss:0.2170
INFO -> 2025-12-08 22:14:26,560: [Evaluate] epoch:2/3, step: 2000/3159, val_acc:0.84748
INFO -> 2025-12-08 22:14:26,999: [Train] epoch:2/3, step: 2000/3159, step_loss:0.2809
INFO -> 2025-12-08 22:15:30,519: [Evaluate] epoch:2/3, step: 2050/3159, val_acc:0.84289
INFO -> 2025-12-08 22:15:30,937: [Train] epoch:2/3, step: 2050/3159, step_loss:0.2603
INFO -> 2025-12-08 22:16:35,471: [Evaluate] epoch:2/3, step: 2100/3159, val_acc:0.84977
INFO -> 2025-12-08 22:16:35,897: [Evaluate] best accuracy performance has been updated: 0.84748 -> 0.84977
INFO -> 2025-12-08 22:16:36,384: [Train] epoch:2/3, step: 2100/3159, step_loss:0.2907
INFO -> 2025-12-08 22:16:45,467: [Epoch 2] train_epoch_loss = 0.0042,  ---- val_acc = 0.8486,  [1340.8s]
INFO -> 2025-12-08 22:17:22,249: [Evaluate] epoch:3/3, step: 2150/3159, val_acc:0.84977
INFO -> 2025-12-08 22:17:22,674: [Train] epoch:3/3, step: 2150/3159, step_loss:0.0863
INFO -> 2025-12-08 22:18:26,393: [Evaluate] epoch:3/3, step: 2200/3159, val_acc:0.84748
INFO -> 2025-12-08 22:18:26,870: [Train] epoch:3/3, step: 2200/3159, step_loss:0.1167
INFO -> 2025-12-08 22:19:26,998: [Evaluate] epoch:3/3, step: 2250/3159, val_acc:0.85206
INFO -> 2025-12-08 22:19:27,379: [Evaluate] best accuracy performance has been updated: 0.84977 -> 0.85206
INFO -> 2025-12-08 22:19:27,821: [Train] epoch:3/3, step: 2250/3159, step_loss:0.1822
INFO -> 2025-12-08 22:20:30,920: [Evaluate] epoch:3/3, step: 2300/3159, val_acc:0.84404
INFO -> 2025-12-08 22:20:31,353: [Train] epoch:3/3, step: 2300/3159, step_loss:0.1712
INFO -> 2025-12-08 22:21:34,268: [Evaluate] epoch:3/3, step: 2350/3159, val_acc:0.83945
INFO -> 2025-12-08 22:21:34,693: [Train] epoch:3/3, step: 2350/3159, step_loss:0.2346
INFO -> 2025-12-08 22:22:38,049: [Evaluate] epoch:3/3, step: 2400/3159, val_acc:0.84289
INFO -> 2025-12-08 22:22:38,470: [Train] epoch:3/3, step: 2400/3159, step_loss:0.2396
INFO -> 2025-12-08 22:23:41,680: [Evaluate] epoch:3/3, step: 2450/3159, val_acc:0.84289
INFO -> 2025-12-08 22:23:42,120: [Train] epoch:3/3, step: 2450/3159, step_loss:0.1577
INFO -> 2025-12-08 22:24:42,762: [Evaluate] epoch:3/3, step: 2500/3159, val_acc:0.84633
INFO -> 2025-12-08 22:24:43,188: [Train] epoch:3/3, step: 2500/3159, step_loss:0.2020
INFO -> 2025-12-08 22:25:46,583: [Evaluate] epoch:3/3, step: 2550/3159, val_acc:0.84518
INFO -> 2025-12-08 22:25:47,009: [Train] epoch:3/3, step: 2550/3159, step_loss:0.1844
INFO -> 2025-12-08 22:26:50,276: [Evaluate] epoch:3/3, step: 2600/3159, val_acc:0.84633
INFO -> 2025-12-08 22:26:50,694: [Train] epoch:3/3, step: 2600/3159, step_loss:0.1260
INFO -> 2025-12-08 22:27:53,643: [Evaluate] epoch:3/3, step: 2650/3159, val_acc:0.84748
INFO -> 2025-12-08 22:27:54,074: [Train] epoch:3/3, step: 2650/3159, step_loss:0.2103
INFO -> 2025-12-08 22:28:57,377: [Evaluate] epoch:3/3, step: 2700/3159, val_acc:0.85206
INFO -> 2025-12-08 22:28:57,815: [Train] epoch:3/3, step: 2700/3159, step_loss:0.1601
INFO -> 2025-12-08 22:29:58,103: [Evaluate] epoch:3/3, step: 2750/3159, val_acc:0.84862
INFO -> 2025-12-08 22:29:58,536: [Train] epoch:3/3, step: 2750/3159, step_loss:0.1299
INFO -> 2025-12-08 22:31:01,945: [Evaluate] epoch:3/3, step: 2800/3159, val_acc:0.84977
INFO -> 2025-12-08 22:31:02,366: [Train] epoch:3/3, step: 2800/3159, step_loss:0.1913
INFO -> 2025-12-08 22:32:02,812: [Evaluate] epoch:3/3, step: 2850/3159, val_acc:0.84404
INFO -> 2025-12-08 22:32:03,242: [Train] epoch:3/3, step: 2850/3159, step_loss:0.2271
INFO -> 2025-12-08 22:33:08,070: [Evaluate] epoch:3/3, step: 2900/3159, val_acc:0.84862
INFO -> 2025-12-08 22:33:08,508: [Train] epoch:3/3, step: 2900/3159, step_loss:0.1895
INFO -> 2025-12-08 22:34:11,123: [Evaluate] epoch:3/3, step: 2950/3159, val_acc:0.84977
INFO -> 2025-12-08 22:34:11,557: [Train] epoch:3/3, step: 2950/3159, step_loss:0.2321
INFO -> 2025-12-08 22:35:16,258: [Evaluate] epoch:3/3, step: 3000/3159, val_acc:0.84977
INFO -> 2025-12-08 22:35:16,708: [Train] epoch:3/3, step: 3000/3159, step_loss:0.1232
INFO -> 2025-12-08 22:36:17,319: [Evaluate] epoch:3/3, step: 3050/3159, val_acc:0.84748
INFO -> 2025-12-08 22:36:17,750: [Train] epoch:3/3, step: 3050/3159, step_loss:0.1867
INFO -> 2025-12-08 22:37:20,953: [Evaluate] epoch:3/3, step: 3100/3159, val_acc:0.85092
INFO -> 2025-12-08 22:37:21,409: [Train] epoch:3/3, step: 3100/3159, step_loss:0.0946
INFO -> 2025-12-08 22:38:24,456: [Evaluate] epoch:3/3, step: 3150/3159, val_acc:0.85206
INFO -> 2025-12-08 22:38:24,876: [Train] epoch:3/3, step: 3150/3159, step_loss:0.2234
INFO -> 2025-12-08 22:38:36,792: [Evaluate] epoch:3/3, step: 3158/3159, val_acc:0.85206
INFO -> 2025-12-08 22:38:40,680: [Epoch 3] train_epoch_loss = 0.0028,  ---- val_acc = 0.8521,  [1311.4s]
INFO -> 2025-12-08 22:38:40,680: -- Training done in 4089s.
INFO -> 2025-12-08 22:38:44,487: âœ… Final Dev Accuracy: 0.8521

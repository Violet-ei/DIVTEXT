INFO -> 2025-12-06 21:20:48,241: sst2, args: Namespace(log_path='./log', dataset='sst2', save_path='./trained_model', model_type='bert-base-uncased', epochs=3, num_labels=2, lr=2e-05, max_len=128, batch_size=64, use_cuda=True, num_workers=32, seed=42, log_steps=50, eval_steps=50, eps=1.0, top_k=20, embedding_type='ct_vectors', mapping_strategy='conservative', privatization_strategy='s1', save_stop_words=False)
INFO -> 2025-12-06 21:21:23,127: train_data:67349,dev_data:872,test_data:1821
INFO -> 2025-12-06 21:21:31,994: Init_val_acc: 0.447556
INFO -> 2025-12-06 21:21:31,994: Training model for 3 epochs..
INFO -> 2025-12-06 21:21:32,287: [Train] epoch:1/3, step: 0/3159, step_loss:0.6868
INFO -> 2025-12-06 21:22:14,679: [Evaluate] epoch:1/3, step: 50/3159, val_acc:0.41406
INFO -> 2025-12-06 21:22:14,960: [Train] epoch:1/3, step: 50/3159, step_loss:0.5086
INFO -> 2025-12-06 21:22:57,896: [Evaluate] epoch:1/3, step: 100/3159, val_acc:0.32510
INFO -> 2025-12-06 21:22:58,172: [Train] epoch:1/3, step: 100/3159, step_loss:0.5865
INFO -> 2025-12-06 21:23:41,372: [Evaluate] epoch:1/3, step: 150/3159, val_acc:0.53213
INFO -> 2025-12-06 21:23:41,843: [Evaluate] best accuracy performance has been updated: 0.44756 -> 0.53213
INFO -> 2025-12-06 21:23:42,128: [Train] epoch:1/3, step: 150/3159, step_loss:0.4614
INFO -> 2025-12-06 21:24:25,468: [Evaluate] epoch:1/3, step: 200/3159, val_acc:0.44701
INFO -> 2025-12-06 21:24:25,742: [Train] epoch:1/3, step: 200/3159, step_loss:0.5565
INFO -> 2025-12-06 21:25:09,240: [Evaluate] epoch:1/3, step: 250/3159, val_acc:0.58869
INFO -> 2025-12-06 21:25:09,611: [Evaluate] best accuracy performance has been updated: 0.53213 -> 0.58869
INFO -> 2025-12-06 21:25:09,881: [Train] epoch:1/3, step: 250/3159, step_loss:0.5772
INFO -> 2025-12-06 21:25:53,448: [Evaluate] epoch:1/3, step: 300/3159, val_acc:0.56782
INFO -> 2025-12-06 21:25:53,744: [Train] epoch:1/3, step: 300/3159, step_loss:0.4916
INFO -> 2025-12-06 21:26:37,486: [Evaluate] epoch:1/3, step: 350/3159, val_acc:0.41790
INFO -> 2025-12-06 21:26:37,763: [Train] epoch:1/3, step: 350/3159, step_loss:0.3961
INFO -> 2025-12-06 21:27:21,493: [Evaluate] epoch:1/3, step: 400/3159, val_acc:0.46183
INFO -> 2025-12-06 21:27:21,768: [Train] epoch:1/3, step: 400/3159, step_loss:0.5406
INFO -> 2025-12-06 21:28:05,412: [Evaluate] epoch:1/3, step: 450/3159, val_acc:0.53981
INFO -> 2025-12-06 21:28:05,674: [Train] epoch:1/3, step: 450/3159, step_loss:0.4026
INFO -> 2025-12-06 21:28:49,327: [Evaluate] epoch:1/3, step: 500/3159, val_acc:0.50686
INFO -> 2025-12-06 21:28:49,601: [Train] epoch:1/3, step: 500/3159, step_loss:0.4319
INFO -> 2025-12-06 21:29:33,483: [Evaluate] epoch:1/3, step: 550/3159, val_acc:0.41790
INFO -> 2025-12-06 21:29:33,752: [Train] epoch:1/3, step: 550/3159, step_loss:0.4245
INFO -> 2025-12-06 21:30:17,621: [Evaluate] epoch:1/3, step: 600/3159, val_acc:0.45744
INFO -> 2025-12-06 21:30:17,888: [Train] epoch:1/3, step: 600/3159, step_loss:0.4440
INFO -> 2025-12-06 21:31:01,794: [Evaluate] epoch:1/3, step: 650/3159, val_acc:0.49533
INFO -> 2025-12-06 21:31:02,071: [Train] epoch:1/3, step: 650/3159, step_loss:0.4815
INFO -> 2025-12-06 21:31:45,956: [Evaluate] epoch:1/3, step: 700/3159, val_acc:0.51236
INFO -> 2025-12-06 21:31:46,236: [Train] epoch:1/3, step: 700/3159, step_loss:0.4266
INFO -> 2025-12-06 21:32:30,504: [Evaluate] epoch:1/3, step: 750/3159, val_acc:0.46568
INFO -> 2025-12-06 21:32:30,783: [Train] epoch:1/3, step: 750/3159, step_loss:0.4241
INFO -> 2025-12-06 21:33:14,799: [Evaluate] epoch:1/3, step: 800/3159, val_acc:0.38715
INFO -> 2025-12-06 21:33:15,069: [Train] epoch:1/3, step: 800/3159, step_loss:0.4497
INFO -> 2025-12-06 21:33:59,095: [Evaluate] epoch:1/3, step: 850/3159, val_acc:0.44591
INFO -> 2025-12-06 21:33:59,362: [Train] epoch:1/3, step: 850/3159, step_loss:0.4281
INFO -> 2025-12-06 21:34:43,576: [Evaluate] epoch:1/3, step: 900/3159, val_acc:0.45579
INFO -> 2025-12-06 21:34:43,839: [Train] epoch:1/3, step: 900/3159, step_loss:0.5446
INFO -> 2025-12-06 21:35:27,961: [Evaluate] epoch:1/3, step: 950/3159, val_acc:0.44097
INFO -> 2025-12-06 21:35:28,239: [Train] epoch:1/3, step: 950/3159, step_loss:0.4152
INFO -> 2025-12-06 21:36:12,331: [Evaluate] epoch:1/3, step: 1000/3159, val_acc:0.42614
INFO -> 2025-12-06 21:36:12,601: [Train] epoch:1/3, step: 1000/3159, step_loss:0.4448
INFO -> 2025-12-06 21:36:56,609: [Evaluate] epoch:1/3, step: 1050/3159, val_acc:0.50357
INFO -> 2025-12-06 21:36:56,883: [Train] epoch:1/3, step: 1050/3159, step_loss:0.4484
INFO -> 2025-12-06 21:37:06,027: [Epoch 1] train_epoch_loss = 0.0076,  ---- val_acc = 0.4421,  [926.2s]
INFO -> 2025-12-06 21:37:47,598: [Evaluate] epoch:2/3, step: 1100/3159, val_acc:0.41351
INFO -> 2025-12-06 21:37:47,864: [Train] epoch:2/3, step: 1100/3159, step_loss:0.2937
INFO -> 2025-12-06 21:38:32,103: [Evaluate] epoch:2/3, step: 1150/3159, val_acc:0.50412
INFO -> 2025-12-06 21:38:32,380: [Train] epoch:2/3, step: 1150/3159, step_loss:0.3361
INFO -> 2025-12-06 21:39:16,512: [Evaluate] epoch:2/3, step: 1200/3159, val_acc:0.47172
INFO -> 2025-12-06 21:39:16,787: [Train] epoch:2/3, step: 1200/3159, step_loss:0.4650
INFO -> 2025-12-06 21:40:00,831: [Evaluate] epoch:2/3, step: 1250/3159, val_acc:0.34651
INFO -> 2025-12-06 21:40:01,115: [Train] epoch:2/3, step: 1250/3159, step_loss:0.2812
INFO -> 2025-12-06 21:40:45,273: [Evaluate] epoch:2/3, step: 1300/3159, val_acc:0.48710
INFO -> 2025-12-06 21:40:45,554: [Train] epoch:2/3, step: 1300/3159, step_loss:0.5287
INFO -> 2025-12-06 21:41:29,943: [Evaluate] epoch:2/3, step: 1350/3159, val_acc:0.48051
INFO -> 2025-12-06 21:41:30,218: [Train] epoch:2/3, step: 1350/3159, step_loss:0.3123
INFO -> 2025-12-06 21:42:14,320: [Evaluate] epoch:2/3, step: 1400/3159, val_acc:0.57002
INFO -> 2025-12-06 21:42:14,593: [Train] epoch:2/3, step: 1400/3159, step_loss:0.3127
INFO -> 2025-12-06 21:42:58,676: [Evaluate] epoch:2/3, step: 1450/3159, val_acc:0.44865
INFO -> 2025-12-06 21:42:58,946: [Train] epoch:2/3, step: 1450/3159, step_loss:0.3570
INFO -> 2025-12-06 21:43:43,088: [Evaluate] epoch:2/3, step: 1500/3159, val_acc:0.49368
INFO -> 2025-12-06 21:43:43,364: [Train] epoch:2/3, step: 1500/3159, step_loss:0.4516
INFO -> 2025-12-06 21:44:27,424: [Evaluate] epoch:2/3, step: 1550/3159, val_acc:0.45964
INFO -> 2025-12-06 21:44:27,698: [Train] epoch:2/3, step: 1550/3159, step_loss:0.2644
INFO -> 2025-12-06 21:45:12,087: [Evaluate] epoch:2/3, step: 1600/3159, val_acc:0.51510
INFO -> 2025-12-06 21:45:12,360: [Train] epoch:2/3, step: 1600/3159, step_loss:0.3199
INFO -> 2025-12-06 21:45:56,469: [Evaluate] epoch:2/3, step: 1650/3159, val_acc:0.49478
INFO -> 2025-12-06 21:45:56,739: [Train] epoch:2/3, step: 1650/3159, step_loss:0.3866
INFO -> 2025-12-06 21:46:40,933: [Evaluate] epoch:2/3, step: 1700/3159, val_acc:0.54530
INFO -> 2025-12-06 21:46:41,205: [Train] epoch:2/3, step: 1700/3159, step_loss:0.3453
INFO -> 2025-12-06 21:47:25,493: [Evaluate] epoch:2/3, step: 1750/3159, val_acc:0.47886
INFO -> 2025-12-06 21:47:25,763: [Train] epoch:2/3, step: 1750/3159, step_loss:0.3478
INFO -> 2025-12-06 21:48:09,972: [Evaluate] epoch:2/3, step: 1800/3159, val_acc:0.48874
INFO -> 2025-12-06 21:48:10,243: [Train] epoch:2/3, step: 1800/3159, step_loss:0.2458
INFO -> 2025-12-06 21:48:54,411: [Evaluate] epoch:2/3, step: 1850/3159, val_acc:0.49039
INFO -> 2025-12-06 21:48:54,691: [Train] epoch:2/3, step: 1850/3159, step_loss:0.2695
INFO -> 2025-12-06 21:49:39,064: [Evaluate] epoch:2/3, step: 1900/3159, val_acc:0.48105
INFO -> 2025-12-06 21:49:39,336: [Train] epoch:2/3, step: 1900/3159, step_loss:0.3502
INFO -> 2025-12-06 21:50:23,503: [Evaluate] epoch:2/3, step: 1950/3159, val_acc:0.49973
INFO -> 2025-12-06 21:50:23,774: [Train] epoch:2/3, step: 1950/3159, step_loss:0.2815
INFO -> 2025-12-06 21:51:07,987: [Evaluate] epoch:2/3, step: 2000/3159, val_acc:0.45634
INFO -> 2025-12-06 21:51:08,262: [Train] epoch:2/3, step: 2000/3159, step_loss:0.2830
INFO -> 2025-12-06 21:51:52,411: [Evaluate] epoch:2/3, step: 2050/3159, val_acc:0.42120
INFO -> 2025-12-06 21:51:52,679: [Train] epoch:2/3, step: 2050/3159, step_loss:0.2337
INFO -> 2025-12-06 21:52:36,865: [Evaluate] epoch:2/3, step: 2100/3159, val_acc:0.48710
INFO -> 2025-12-06 21:52:37,137: [Train] epoch:2/3, step: 2100/3159, step_loss:0.2575
INFO -> 2025-12-06 21:52:48,558: [Epoch 2] train_epoch_loss = 0.0053,  ---- val_acc = 0.4662,  [934.7s]
INFO -> 2025-12-06 21:53:27,996: [Evaluate] epoch:3/3, step: 2150/3159, val_acc:0.49918
INFO -> 2025-12-06 21:53:28,272: [Train] epoch:3/3, step: 2150/3159, step_loss:0.4985
INFO -> 2025-12-06 21:54:12,598: [Evaluate] epoch:3/3, step: 2200/3159, val_acc:0.46129
INFO -> 2025-12-06 21:54:12,878: [Train] epoch:3/3, step: 2200/3159, step_loss:0.2647
INFO -> 2025-12-06 21:54:57,081: [Evaluate] epoch:3/3, step: 2250/3159, val_acc:0.50467
INFO -> 2025-12-06 21:54:57,361: [Train] epoch:3/3, step: 2250/3159, step_loss:0.3113
INFO -> 2025-12-06 21:55:41,589: [Evaluate] epoch:3/3, step: 2300/3159, val_acc:0.47392
INFO -> 2025-12-06 21:55:41,858: [Train] epoch:3/3, step: 2300/3159, step_loss:0.2472
INFO -> 2025-12-06 21:56:26,216: [Evaluate] epoch:3/3, step: 2350/3159, val_acc:0.48215
INFO -> 2025-12-06 21:56:26,489: [Train] epoch:3/3, step: 2350/3159, step_loss:0.2438
INFO -> 2025-12-06 21:57:10,711: [Evaluate] epoch:3/3, step: 2400/3159, val_acc:0.51455
INFO -> 2025-12-06 21:57:10,986: [Train] epoch:3/3, step: 2400/3159, step_loss:0.1231
INFO -> 2025-12-06 21:57:55,318: [Evaluate] epoch:3/3, step: 2450/3159, val_acc:0.48764
INFO -> 2025-12-06 21:57:55,595: [Train] epoch:3/3, step: 2450/3159, step_loss:0.1449
INFO -> 2025-12-06 21:58:40,015: [Evaluate] epoch:3/3, step: 2500/3159, val_acc:0.45140
INFO -> 2025-12-06 21:58:40,291: [Train] epoch:3/3, step: 2500/3159, step_loss:0.3738
INFO -> 2025-12-06 21:59:24,699: [Evaluate] epoch:3/3, step: 2550/3159, val_acc:0.45579
INFO -> 2025-12-06 21:59:24,974: [Train] epoch:3/3, step: 2550/3159, step_loss:0.2208
INFO -> 2025-12-06 22:00:09,276: [Evaluate] epoch:3/3, step: 2600/3159, val_acc:0.50741
INFO -> 2025-12-06 22:00:09,554: [Train] epoch:3/3, step: 2600/3159, step_loss:0.1691
INFO -> 2025-12-06 22:00:53,887: [Evaluate] epoch:3/3, step: 2650/3159, val_acc:0.46019
INFO -> 2025-12-06 22:00:54,163: [Train] epoch:3/3, step: 2650/3159, step_loss:0.2932
INFO -> 2025-12-06 22:01:38,543: [Evaluate] epoch:3/3, step: 2700/3159, val_acc:0.47831
INFO -> 2025-12-06 22:01:38,817: [Train] epoch:3/3, step: 2700/3159, step_loss:0.2144
INFO -> 2025-12-06 22:02:23,100: [Evaluate] epoch:3/3, step: 2750/3159, val_acc:0.45470
INFO -> 2025-12-06 22:02:23,378: [Train] epoch:3/3, step: 2750/3159, step_loss:0.1777
INFO -> 2025-12-06 22:03:07,620: [Evaluate] epoch:3/3, step: 2800/3159, val_acc:0.49314
INFO -> 2025-12-06 22:03:07,900: [Train] epoch:3/3, step: 2800/3159, step_loss:0.2756
INFO -> 2025-12-06 22:03:52,216: [Evaluate] epoch:3/3, step: 2850/3159, val_acc:0.49204
INFO -> 2025-12-06 22:03:52,487: [Train] epoch:3/3, step: 2850/3159, step_loss:0.1747
INFO -> 2025-12-06 22:04:36,906: [Evaluate] epoch:3/3, step: 2900/3159, val_acc:0.48051
INFO -> 2025-12-06 22:04:37,188: [Train] epoch:3/3, step: 2900/3159, step_loss:0.3326
INFO -> 2025-12-06 22:05:21,504: [Evaluate] epoch:3/3, step: 2950/3159, val_acc:0.48600
INFO -> 2025-12-06 22:05:21,781: [Train] epoch:3/3, step: 2950/3159, step_loss:0.1598
INFO -> 2025-12-06 22:06:06,227: [Evaluate] epoch:3/3, step: 3000/3159, val_acc:0.46403
INFO -> 2025-12-06 22:06:06,501: [Train] epoch:3/3, step: 3000/3159, step_loss:0.1982
INFO -> 2025-12-06 22:06:50,965: [Evaluate] epoch:3/3, step: 3050/3159, val_acc:0.49533
INFO -> 2025-12-06 22:06:51,233: [Train] epoch:3/3, step: 3050/3159, step_loss:0.1401
INFO -> 2025-12-06 22:07:35,785: [Evaluate] epoch:3/3, step: 3100/3159, val_acc:0.48270
INFO -> 2025-12-06 22:07:36,053: [Train] epoch:3/3, step: 3100/3159, step_loss:0.2044
INFO -> 2025-12-06 22:08:20,270: [Evaluate] epoch:3/3, step: 3150/3159, val_acc:0.47611
INFO -> 2025-12-06 22:08:20,552: [Train] epoch:3/3, step: 3150/3159, step_loss:0.1699
INFO -> 2025-12-06 22:08:33,990: [Evaluate] epoch:3/3, step: 3158/3159, val_acc:0.47611
INFO -> 2025-12-06 22:08:42,016: [Epoch 3] train_epoch_loss = 0.0039,  ---- val_acc = 0.4761,  [945.6s]
INFO -> 2025-12-06 22:08:42,016: -- Training done in 2830s.
INFO -> 2025-12-06 22:08:50,031: test acc = 0.5887.
